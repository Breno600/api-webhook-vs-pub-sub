segue log completo

Exec using JSCH
Connecting to 10.218.238.144 ....
Connection to 10.218.238.144 established
Executing command ...
export GIT_TAG=dev000006
Clonando repo em /tmp/tmp.STk45985g6...
Cloning into '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef'...
remote: Enumerating objects: 973, done.
remote: Counting objects:   0% (1/923)
remote: Counting objects:   1% (10/923)
remote: Counting objects:   2% (19/923)
remote: Counting objects:   3% (28/923)
remote: Counting objects:   4% (37/923)
remote: Counting objects:   5% (47/923)
remote: Counting objects:   6% (56/923)
remote: Counting objects:   7% (65/923)
remote: Counting objects:   8% (74/923)
remote: Counting objects:   9% (84/923)
remote: Counting objects:  10% (93/923)
remote: Counting objects:  11% (102/923)
remote: Counting objects:  12% (111/923)
remote: Counting objects:  13% (120/923)
remote: Counting objects:  14% (130/923)
remote: Counting objects:  15% (139/923)
remote: Counting objects:  16% (148/923)
remote: Counting objects:  17% (157/923)
remote: Counting objects:  18% (167/923)
remote: Counting objects:  19% (176/923)
remote: Counting objects:  20% (185/923)
remote: Counting objects:  21% (194/923)
remote: Counting objects:  22% (204/923)
remote: Counting objects:  23% (213/923)
remote: Counting objects:  24% (222/923)
remote: Counting objects:  25% (231/923)
remote: Counting objects:  26% (240/923)
remote: Counting objects:  27% (250/923)
remote: Counting objects:  28% (259/923)
remote: Counting objects:  29% (268/923)
remote: Counting objects:  30% (277/923)
remote: Counting objects:  31% (287/923)
remote: Counting objects:  32% (296/923)
remote: Counting objects:  33% (305/923)
remote: Counting objects:  34% (314/923)
remote: Counting objects:  35% (324/923)
remote: Counting objects:  36% (333/923)
remote: Counting objects:  37% (342/923)
remote: Counting objects:  38% (351/923)
remote: Counting objects:  39% (360/923)
remote: Counting objects:  40% (370/923)
remote: Counting objects:  41% (379/923)
remote: Counting objects:  42% (388/923)
remote: Counting objects:  43% (397/923)
remote: Counting objects:  44% (407/923)
remote: Counting objects:  45% (416/923)
remote: Counting objects:  46% (425/923)
remote: Counting objects:  47% (434/923)
remote: Counting objects:  48% (444/923)
remote: Counting objects:  49% (453/923)
remote: Counting objects:  50% (462/923)
remote: Counting objects:  51% (471/923)
remote: Counting objects:  52% (480/923)
remote: Counting objects:  53% (490/923)
remote: Counting objects:  54% (499/923)
remote: Counting objects:  55% (508/923)
remote: Counting objects:  56% (517/923)
remote: Counting objects:  57% (527/923)
remote: Counting objects:  58% (536/923)
remote: Counting objects:  59% (545/923)
remote: Counting objects:  60% (554/923)
remote: Counting objects:  61% (564/923)
remote: Counting objects:  62% (573/923)
remote: Counting objects:  63% (582/923)
remote: Counting objects:  64% (591/923)
remote: Counting objects:  65% (600/923)
remote: Counting objects:  66% (610/923)
remote: Counting objects:  67% (619/923)
remote: Counting objects:  68% (628/923)
remote: Counting objects:  69% (637/923)
remote: Counting objects:  70% (647/923)
remote: Counting objects:  71% (656/923)
remote: Counting objects:  72% (665/923)
remote: Counting objects:  73% (674/923)
remote: Counting objects:  74% (684/923)
remote: Counting objects:  75% (693/923)
remote: Counting objects:  76% (702/923)
remote: Counting objects:  77% (711/923)
remote: Counting objects:  78% (720/923)
remote: Counting objects:  79% (730/923)
remote: Counting objects:  80% (739/923)
remote: Counting objects:  81% (748/923)
remote: Counting objects:  82% (757/923)
remote: Counting objects:  83% (767/923)
remote: Counting objects:  84% (776/923)
remote: Counting objects:  85% (785/923)
remote: Counting objects:  86% (794/923)
remote: Counting objects:  87% (804/923)
remote: Counting objects:  88% (813/923)
remote: Counting objects:  89% (822/923)
remote: Counting objects:  90% (831/923)
remote: Counting objects:  91% (840/923)
remote: Counting objects:  92% (850/923)
remote: Counting objects:  93% (859/923)
remote: Counting objects:  94% (868/923)
remote: Counting objects:  95% (877/923)
remote: Counting objects:  96% (887/923)
remote: Counting objects:  97% (896/923)
remote: Counting objects:  98% (905/923)
remote: Counting objects:  99% (914/923)
remote: Counting objects: 100% (923/923)
remote: Counting objects: 100% (923/923), done.
remote: Compressing objects:   0% (1/908)
remote: Compressing objects:   1% (10/908)
remote: Compressing objects:   2% (19/908)
remote: Compressing objects:   3% (28/908)
remote: Compressing objects:   4% (37/908)
remote: Compressing objects:   5% (46/908)
remote: Compressing objects:   6% (55/908)
remote: Compressing objects:   7% (64/908)
remote: Compressing objects:   8% (73/908)
remote: Compressing objects:   9% (82/908)
remote: Compressing objects:  10% (91/908)
remote: Compressing objects:  11% (100/908)
remote: Compressing objects:  12% (109/908)
remote: Compressing objects:  13% (119/908)
remote: Compressing objects:  14% (128/908)
remote: Compressing objects:  15% (137/908)
remote: Compressing objects:  16% (146/908)
remote: Compressing objects:  17% (155/908)
remote: Compressing objects:  18% (164/908)
remote: Compressing objects:  19% (173/908)
remote: Compressing objects:  20% (182/908)
remote: Compressing objects:  21% (191/908)
remote: Compressing objects:  22% (200/908)
remote: Compressing objects:  23% (209/908)
remote: Compressing objects:  24% (218/908)
remote: Compressing objects:  25% (227/908)
remote: Compressing objects:  26% (237/908)
remote: Compressing objects:  27% (246/908)
remote: Compressing objects:  28% (255/908)
remote: Compressing objects:  29% (264/908)
remote: Compressing objects:  30% (273/908)
remote: Compressing objects:  31% (282/908)
remote: Compressing objects:  32% (291/908)
remote: Compressing objects:  33% (300/908)
remote: Compressing objects:  34% (309/908)
remote: Compressing objects:  35% (318/908)
remote: Compressing objects:  36% (327/908)
remote: Compressing objects:  37% (336/908)
remote: Compressing objects:  38% (346/908)
remote: Compressing objects:  39% (355/908)
remote: Compressing objects:  40% (364/908)
remote: Compressing objects:  41% (373/908)
remote: Compressing objects:  42% (382/908)
remote: Compressing objects:  43% (391/908)
remote: Compressing objects:  44% (400/908)
remote: Compressing objects:  45% (409/908)
remote: Compressing objects:  46% (418/908)
remote: Compressing objects:  47% (427/908)
remote: Compressing objects:  48% (436/908)
remote: Compressing objects:  49% (445/908)
remote: Compressing objects:  50% (454/908)
remote: Compressing objects:  51% (464/908)
remote: Compressing objects:  52% (473/908)
remote: Compressing objects:  53% (482/908)
remote: Compressing objects:  54% (491/908)
remote: Compressing objects:  55% (500/908)
remote: Compressing objects:  56% (509/908)
remote: Compressing objects:  57% (518/908)
remote: Compressing objects:  58% (527/908)
remote: Compressing objects:  59% (536/908)
remote: Compressing objects:  60% (545/908)
remote: Compressing objects:  61% (554/908)
remote: Compressing objects:  62% (563/908)
remote: Compressing objects:  63% (573/908)
remote: Compressing objects:  64% (582/908)
remote: Compressing objects:  65% (591/908)
remote: Compressing objects:  66% (600/908)
remote: Compressing objects:  67% (609/908)
remote: Compressing objects:  68% (618/908)
remote: Compressing objects:  69% (627/908)
remote: Compressing objects:  70% (636/908)
remote: Compressing objects:  71% (645/908)
remote: Compressing objects:  72% (654/908)
remote: Compressing objects:  73% (663/908)
remote: Compressing objects:  74% (672/908)
remote: Compressing objects:  75% (681/908)
remote: Compressing objects:  76% (691/908)
remote: Compressing objects:  77% (700/908)
remote: Compressing objects:  78% (709/908)
remote: Compressing objects:  79% (718/908)
remote: Compressing objects:  80% (727/908)
remote: Compressing objects:  81% (736/908)
remote: Compressing objects:  82% (745/908)
remote: Compressing objects:  83% (754/908)
remote: Compressing objects:  84% (763/908)
remote: Compressing objects:  85% (772/908)
remote: Compressing objects:  86% (781/908)
remote: Compressing objects:  87% (790/908)
remote: Compressing objects:  88% (800/908)
remote: Compressing objects:  89% (809/908)
remote: Compressing objects:  90% (818/908)
remote: Compressing objects:  91% (827/908)
remote: Compressing objects:  92% (836/908)
remote: Compressing objects:  93% (845/908)
remote: Compressing objects:  94% (854/908)
remote: Compressing objects:  95% (863/908)
remote: Compressing objects:  96% (872/908)
remote: Compressing objects:  97% (881/908)
remote: Compressing objects:  98% (890/908)
remote: Compressing objects:  99% (899/908)
remote: Compressing objects: 100% (908/908)
remote: Compressing objects: 100% (908/908), done.
Receiving objects:   0% (1/973)
Receiving objects:   1% (10/973)
Receiving objects:   2% (20/973)
Receiving objects:   3% (30/973)
Receiving objects:   4% (39/973)
Receiving objects:   5% (49/973)
Receiving objects:   6% (59/973)
Receiving objects:   7% (69/973)
Receiving objects:   8% (78/973)
Receiving objects:   9% (88/973)
Receiving objects:  10% (98/973)
Receiving objects:  11% (108/973)
Receiving objects:  12% (117/973)
Receiving objects:  13% (127/973)
Receiving objects:  14% (137/973)
Receiving objects:  15% (146/973)
Receiving objects:  16% (156/973)
Receiving objects:  17% (166/973)
Receiving objects:  18% (176/973)
Receiving objects:  19% (185/973)
Receiving objects:  20% (195/973)
Receiving objects:  21% (205/973)
Receiving objects:  22% (215/973)
Receiving objects:  23% (224/973)
Receiving objects:  24% (234/973)
Receiving objects:  25% (244/973)
Receiving objects:  26% (253/973)
Receiving objects:  27% (263/973)
Receiving objects:  28% (273/973)
Receiving objects:  29% (283/973)
Receiving objects:  30% (292/973)
Receiving objects:  31% (302/973)
Receiving objects:  32% (312/973)
Receiving objects:  33% (322/973)
Receiving objects:  34% (331/973)
Receiving objects:  35% (341/973)
Receiving objects:  36% (351/973)
Receiving objects:  37% (361/973)
Receiving objects:  38% (370/973)
Receiving objects:  39% (380/973)
Receiving objects:  40% (390/973)
Receiving objects:  41% (399/973)
Receiving objects:  42% (409/973)
Receiving objects:  43% (419/973)
Receiving objects:  44% (429/973)
Receiving objects:  45% (438/973)
Receiving objects:  46% (448/973)
Receiving objects:  47% (458/973)
Receiving objects:  48% (468/973)
Receiving objects:  49% (477/973)
Receiving objects:  50% (487/973)
Receiving objects:  51% (497/973)
Receiving objects:  52% (506/973)
Receiving objects:  53% (516/973)
Receiving objects:  54% (526/973)
Receiving objects:  55% (536/973)
Receiving objects:  56% (545/973)
Receiving objects:  57% (555/973)
Receiving objects:  58% (565/973)
Receiving objects:  59% (575/973)
Receiving objects:  60% (584/973)
Receiving objects:  61% (594/973)
Receiving objects:  62% (604/973)
Receiving objects:  63% (613/973)
Receiving objects:  64% (623/973)
Receiving objects:  65% (633/973)
Receiving objects:  66% (643/973)
Receiving objects:  67% (652/973)
Receiving objects:  68% (662/973)
Receiving objects:  69% (672/973)
Receiving objects:  70% (682/973)
Receiving objects:  71% (691/973)
Receiving objects:  72% (701/973)
Receiving objects:  73% (711/973)
Receiving objects:  74% (721/973)
Receiving objects:  75% (730/973)
Receiving objects:  76% (740/973)
Receiving objects:  77% (750/973)
Receiving objects:  78% (759/973)
Receiving objects:  79% (769/973)
Receiving objects:  80% (779/973)
Receiving objects:  81% (789/973)
Receiving objects:  82% (798/973)
Receiving objects:  83% (808/973)
remote: Total 973 (delta 633), reused 0 (delta 0), pack-reused 50
Receiving objects:  84% (818/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  85% (828/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  86% (837/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  87% (847/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  88% (857/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  89% (866/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  90% (876/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  91% (886/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  92% (896/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  93% (905/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  94% (915/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  95% (925/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  96% (935/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  97% (944/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  98% (954/973), 707.77 KiB | 1.34 MiB/s
Receiving objects:  99% (964/973), 707.77 KiB | 1.34 MiB/s
Receiving objects: 100% (973/973), 707.77 KiB | 1.34 MiB/s
Receiving objects: 100% (973/973), 947.88 KiB | 1.73 MiB/s, done.
Resolving deltas:   0% (0/652)
Resolving deltas:   1% (7/652)
Resolving deltas:   2% (14/652)
Resolving deltas:   3% (20/652)
Resolving deltas:   4% (27/652)
Resolving deltas:   5% (33/652)
Resolving deltas:   6% (40/652)
Resolving deltas:   7% (46/652)
Resolving deltas:   8% (53/652)
Resolving deltas:   9% (59/652)
Resolving deltas:  10% (66/652)
Resolving deltas:  11% (72/652)
Resolving deltas:  12% (79/652)
Resolving deltas:  13% (85/652)
Resolving deltas:  14% (92/652)
Resolving deltas:  15% (98/652)
Resolving deltas:  16% (105/652)
Resolving deltas:  17% (111/652)
Resolving deltas:  18% (118/652)
Resolving deltas:  19% (124/652)
Resolving deltas:  20% (131/652)
Resolving deltas:  21% (137/652)
Resolving deltas:  22% (144/652)
Resolving deltas:  23% (150/652)
Resolving deltas:  24% (157/652)
Resolving deltas:  25% (163/652)
Resolving deltas:  26% (170/652)
Resolving deltas:  27% (177/652)
Resolving deltas:  28% (183/652)
Resolving deltas:  29% (190/652)
Resolving deltas:  30% (196/652)
Resolving deltas:  31% (203/652)
Resolving deltas:  32% (209/652)
Resolving deltas:  33% (216/652)
Resolving deltas:  34% (222/652)
Resolving deltas:  35% (229/652)
Resolving deltas:  36% (235/652)
Resolving deltas:  37% (242/652)
Resolving deltas:  38% (248/652)
Resolving deltas:  39% (255/652)
Resolving deltas:  40% (261/652)
Resolving deltas:  41% (268/652)
Resolving deltas:  42% (274/652)
Resolving deltas:  43% (281/652)
Resolving deltas:  44% (287/652)
Resolving deltas:  45% (294/652)
Resolving deltas:  46% (300/652)
Resolving deltas:  47% (307/652)
Resolving deltas:  48% (313/652)
Resolving deltas:  49% (320/652)
Resolving deltas:  50% (326/652)
Resolving deltas:  51% (333/652)
Resolving deltas:  52% (340/652)
Resolving deltas:  53% (346/652)
Resolving deltas:  54% (353/652)
Resolving deltas:  55% (359/652)
Resolving deltas:  56% (366/652)
Resolving deltas:  57% (372/652)
Resolving deltas:  58% (379/652)
Resolving deltas:  59% (385/652)
Resolving deltas:  60% (392/652)
Resolving deltas:  61% (398/652)
Resolving deltas:  62% (405/652)
Resolving deltas:  63% (411/652)
Resolving deltas:  64% (418/652)
Resolving deltas:  65% (424/652)
Resolving deltas:  66% (431/652)
Resolving deltas:  67% (437/652)
Resolving deltas:  68% (444/652)
Resolving deltas:  69% (450/652)
Resolving deltas:  70% (457/652)
Resolving deltas:  71% (463/652)
Resolving deltas:  72% (470/652)
Resolving deltas:  73% (476/652)
Resolving deltas:  74% (483/652)
Resolving deltas:  75% (489/652)
Resolving deltas:  76% (496/652)
Resolving deltas:  77% (503/652)
Resolving deltas:  78% (510/652)
Resolving deltas:  79% (516/652)
Resolving deltas:  80% (522/652)
Resolving deltas:  81% (529/652)
Resolving deltas:  82% (535/652)
Resolving deltas:  83% (542/652)
Resolving deltas:  84% (548/652)
Resolving deltas:  85% (555/652)
Resolving deltas:  86% (561/652)
Resolving deltas:  87% (568/652)
Resolving deltas:  88% (574/652)
Resolving deltas:  89% (581/652)
Resolving deltas:  90% (587/652)
Resolving deltas:  91% (594/652)
Resolving deltas:  92% (600/652)
Resolving deltas:  93% (607/652)
Resolving deltas:  94% (613/652)
Resolving deltas:  95% (620/652)
Resolving deltas:  96% (626/652)
Resolving deltas:  97% (633/652)
Resolving deltas:  98% (639/652)
Resolving deltas:  99% (646/652)
Resolving deltas: 100% (652/652)
Resolving deltas: 100% (652/652), done.
== PIPELINE PREDEPLOY ==
TAG   : dev000006
EXEC  : execution/machine_list_dev.yml
BRANCH: develop-testes
[WARNING]: Unable to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/localhost as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/deploy_from_status.yml with auto plugin: no root 'plugin' key
found, '/tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/deploy_from_status.yml' is not a valid YAML inventory plugin
config file
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/deploy_from_status.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/deploy_from_status.yml with ini plugin: Invalid host pattern
'---' supplied, '---' is normally a sign this is a YAML file.
[WARNING]: Unable to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/deploy_from_status.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/deploy_per_machine.yml with auto plugin: no root 'plugin' key
found, '/tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/deploy_per_machine.yml' is not a valid YAML inventory plugin
config file
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/deploy_per_machine.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/deploy_per_machine.yml with ini plugin: Invalid host pattern
'---' supplied, '---' is normally a sign this is a YAML file.
[WARNING]: Unable to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/deploy_per_machine.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/harness_filestore_upload.yml with auto plugin: no root 'plugin'
key found, '/tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/harness_filestore_upload.yml' is not a valid YAML inventory
plugin config file
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/harness_filestore_upload.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/harness_filestore_upload.yml with ini plugin: Invalid host
pattern '---' supplied, '---' is normally a sign this is a YAML file.
[WARNING]: Unable to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/harness_filestore_upload.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml with auto plugin: no root 'plugin'
key found, '/tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml' is not a valid YAML inventory
plugin config file
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml with ini plugin:
/tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml:5: Expected key=value host variable
assignment, got: name:
[WARNING]: Unable to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_per_machine.yml with auto plugin: no root 'plugin' key
found, '/tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_per_machine.yml' is not a valid YAML inventory plugin
config file
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_per_machine.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_per_machine.yml with ini plugin: Invalid host pattern
'---' supplied, '---' is normally a sign this is a YAML file.
[WARNING]: Unable to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/predeploy_per_machine.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml with auto plugin: no root 'plugin' key
found, '/tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml' is not a valid YAML inventory plugin
config file
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml with ini plugin:
/tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml:5: Expected key=value host variable
assignment, got: name:
[WARNING]: Unable to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_per_machine.yml with auto plugin: no root 'plugin' key
found, '/tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_per_machine.yml' is not a valid YAML inventory plugin
config file
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_per_machine.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_per_machine.yml with ini plugin: Invalid host pattern
'---' supplied, '---' is normally a sign this is a YAML file.
[WARNING]: Unable to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible/rollback_per_machine.yml as an inventory source
[WARNING]: Unable to parse /tmp/tmp.STk45985g6/elastic-compute-cloud-
sitef/ansible as an inventory source
[WARNING]: No inventory was parsed, only implicit localhost is available
[WARNING]: provided hosts list is empty, only localhost is available. Note that
the implicit localhost does not match 'all'
PLAY [Predeploy a partir do arquivo de execução] *******************************
TASK [Gathering Facts] *********************************************************
ok: [localhost]
TASK [Resolver filestore_env e filestore_base_dir sem recursão] ****************
ok: [localhost]
TASK [Mostrar variáveis de entrada e resolvidas] *******************************
ok: [localhost] => {
    "msg": [
        "execution_file_name          = execution/machine_list_dev.yml",
        "deployment_ref               = dev000006",
        "repo_root_resolved           = /tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/..",
        "status_dir_resolved          = /tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../status/dev000006",
        "filestore_env_resolved       = dev",
        "filestore_base_dir_resolved  = dev/dev000006",
        "nexus_base_url               = https://nexus-ci.onefiserv.net/repository/raw-apm0004548-dev"
    ]
}
TASK [Criar diretório de status da TAG] ****************************************
changed: [localhost]
TASK [Carregar arquivo de execução] ********************************************
ok: [localhost]
TASK [Falhar se não tiver máquinas no arquivo de execução] *********************
skipping: [localhost]
TASK [Executar pré-deploy por máquina] *****************************************
included: /tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/predeploy_per_machine.yml for localhost => (item=sitef-02)
TASK [Predeploy | Resolver nome da máquina atual] ******************************
ok: [localhost]
TASK [Predeploy | Validar vars mínimas] ****************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
TASK [Predeploy | Definir paths base do repositório] ***************************
ok: [localhost]
TASK [Predeploy | Definir candidatos de arquivo da máquina] ********************
ok: [localhost]
TASK [Predeploy | Verificar candidatos] ****************************************
ok: [localhost] => (item=/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../execution/machines/sitef-02.yml)
ok: [localhost] => (item=/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../execution/sitef-02.yml)
ok: [localhost] => (item=/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../machines/sitef-02.yml)
ok: [localhost] => (item=/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../inventory/machines/sitef-02.yml)
TASK [Predeploy | Selecionar machine_file existente] ***************************
skipping: [localhost] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../execution/machines/sitef-02.yml', 'follow': False, 'get_md5': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../execution/machines/sitef-02.yml', 'ansible_loop_var': 'item'}) 
skipping: [localhost] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../execution/sitef-02.yml', 'follow': False, 'get_md5': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../execution/sitef-02.yml', 'ansible_loop_var': 'item'}) 
ok: [localhost] => (item={'changed': False, 'stat': {'exists': True, 'path': '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../machines/sitef-02.yml', 'mode': '0640', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1000, 'gid': 1000, 'size': 248, 'inode': 2102512, 'dev': 64775, 'nlink': 1, 'atime': 1766605363.842651, 'mtime': 1766605363.8306508, 'ctime': 1766605363.8306508, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'ec2-user', 'gr_name': 'ec2-user', 'checksum': '005e3367129d5aefc77f49fd9fe62b4e58c51cd5', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '1851863953', 'attributes': [], 'attr_flags': ''}, 'invocation': {'module_args': {'path': '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../machines/sitef-02.yml', 'follow': False, 'get_md5': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../machines/sitef-02.yml', 'ansible_loop_var': 'item'})
skipping: [localhost] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../inventory/machines/sitef-02.yml', 'follow': False, 'get_md5': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/../inventory/machines/sitef-02.yml', 'ansible_loop_var': 'item'}) 
TASK [Predeploy | Falhar se arquivo da máquina não existir] ********************
skipping: [localhost]
TASK [Predeploy | Carregar config da máquina sitef-02] *************************
ok: [localhost]
TASK [Predeploy | Validar package definido] ************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
TASK [Predeploy | Carregar config do pacote sitef-core-0.0.1-0] ****************
ok: [localhost]
TASK [Predeploy | Validar components do pacote] ********************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
TASK [Predeploy | Validar script do pacote] ************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
TASK [Predeploy | Definir usuário alvo padrão] *********************************
ok: [localhost]
TASK [Predeploy | Definir ssh_common_args padrão] ******************************
ok: [localhost]
TASK [Predeploy | Aplicar ProxyJump via bastion (quando necessário)] ***********
skipping: [localhost]
TASK [Predeploy | Registrar host dinâmico para sitef-02] ***********************
changed: [localhost]
TASK [Predeploy | Montar env final (package base + machine override)] **********
ok: [localhost]
TASK [Predeploy | Normalizações] ***********************************************
ok: [localhost]
TASK [Predeploy | Gerar run_id] ************************************************
ok: [localhost]
TASK [Predeploy | Definir arquivos/diretórios locais] **************************
ok: [localhost]
TASK [Predeploy | Definir paths lógicos (File Store) SEPARADOS POR STAGE] ******
ok: [localhost]
TASK [Predeploy | Garantir diretório de status local] **************************
changed: [localhost]
TASK [Predeploy | Garantir arquivo pipeline.log (cumulativo local)] ************
changed: [localhost]
TASK [Predeploy | Verificar se status.json já existe] **************************
ok: [localhost]
TASK [Predeploy | Ler status.json existente (se existir)] **********************
skipping: [localhost]
TASK [Predeploy | Parse do status existente (ou base vazio)] *******************
ok: [localhost]
TASK [Predeploy | Escrever status inicial (predeploy:queued) com history append] ***
changed: [localhost]
TASK [Predeploy | Definir diretórios remotos do pipeline] **********************
ok: [localhost]
TASK [Predeploy | Garantir base do pipeline no host] ***************************
ok: [localhost -> sitef-02(100.99.57.128)] => (item=/opt/SoftwareExpress/sitef-pipeline/deploy/components)
ok: [localhost -> sitef-02(100.99.57.128)] => (item=/opt/SoftwareExpress/sitef-pipeline/deploy/scripts)
ok: [localhost -> sitef-02(100.99.57.128)] => (item=/opt/SoftwareExpress/sitef-pipeline/deploy/scripts/package)
TASK [Predeploy | Limpar pasta de scripts do pacote] ***************************
changed: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Recriar pasta de scripts do pacote] **************************
changed: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Copiar package.yml para o host] ******************************
changed: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Garantir diretórios dos componentes no host] *****************
ok: [localhost -> sitef-02(100.99.57.128)] => (item=packages/linux/sitef-core-0.0.1-0.x86_64.rpm)
TASK [Predeploy | Baixar componentes do Nexus] *********************************
ok: [localhost -> sitef-02(100.99.57.128)] => (item=packages/linux/sitef-core-0.0.1-0.x86_64.rpm)
TASK [Predeploy | Copiar scripts do pacote para o host] ************************
ok: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Executar init_parallel.sh no host (com log + stdout)] ********
changed: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Tail do init_parallel.log (sempre)] **************************
ok: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Montar conteúdo do log (bloco predeploy)] ********************
ok: [localhost]
TASK [Predeploy | Append do bloco no pipeline.log (controller)] ****************
changed: [localhost]
TASK [Predeploy | Carregar conteúdo completo do pipeline.log (controller)] *****
ok: [localhost]
TASK [Predeploy | Ler status.json atual] ***************************************
ok: [localhost]
TASK [Predeploy | Parse do status atual] ***************************************
ok: [localhost]
TASK [Predeploy | Atualizar status final (append em history)] ******************
changed: [localhost]
TASK [Predeploy | Upload JSON + LOG para Harness File Store (sempre)] **********
included: /tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/harness_filestore_upload.yml for localhost
TASK [Harness | Resolver entradas (safe locals)] *******************************
ok: [localhost]
TASK [Harness | Validar mínimos (sem falhar a pipeline)] ***********************
ok: [localhost] => {
    "msg": [
        "hf_endpoint=",
        "hf_account=",
        "hf_org=",
        "hf_project=",
        "hf_deployment_ref=dev000006",
        "hf_machine=sitef-02",
        "hf_stage=predeploy",
        "hf_env=dev"
    ]
}
TASK [Harness | Pular upload se faltar credenciais do Harness] *****************
ok: [localhost] => {
    "msg": "Harness creds ausentes (HARNESS_API_KEY/HARNESS_ACCOUNT_ID/HARNESS_ORG_ID/HARNESS_PROJECT_ID). Pulando upload."
}
TASK [Harness | Resolver paths lógicos (fallback) + nomes safe] ****************
skipping: [localhost]
TASK [Harness | Montar tags] ***************************************************
skipping: [localhost]
TASK [Harness | Criar temp dir (controller)] ***********************************
skipping: [localhost]
TASK [Harness | Escrever LOG temp (controller)] ********************************
fatal: [localhost]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'path'. 'dict object' has no attribute 'path'\n\nThe error appears to be in '/tmp/tmp.STk45985g6/elastic-compute-cloud-sitef/ansible/harness_filestore_upload.yml': line 128, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: \"Harness | Escrever LOG temp (controller)\"\n  ^ here\n"}
PLAY RECAP *********************************************************************
localhost                  : ok=50   changed=11   unreachable=0    failed=1    skipped=7    rescued=0    ignored=0   
Command finished with status FAILURE


segue script no harness
#!/bin/bash
set -euo pipefail

GIT_TOKEN="xXAiJyF1Hx4noamrBSdV"
GIT_TAG="${GIT_TAG:-}"
EXECUTION_FILE_NAME="${EXECUTION_FILE_NAME:-execution/machine_list_dev.yml}"
GIT_BRANCH="${GIT_BRANCH:-develop-testes}"

GIT_USER_NAME="${GIT_USER_NAME:-harness-bot}"
GIT_USER_EMAIL="${GIT_USER_EMAIL:-harness-bot@fiserv.com}"

NEXUS_BASE_URL="${NEXUS_BASE_URL:-https://nexus-ci.onefiserv.net/repository/raw-apm0004548-dev}"
NEXUS_USER="${NEXUS_USER:-AS4hZF20}"
NEXUS_PASSWORD="${NEXUS_PASSWORD:-l7WwGfJd_Grmh-5Kn7B__U8nqgdNWh1XhrYtVQQ5I_6k}"

HARNESS_X_API_KEY="${HARNESS_X_API_KEY:-pat.fgDto6qoTT6ctfZS9eWbEw.693f147c43bfca2e849b46f4.WtMpaUZG5pxwDZcIkzl0}"

FILESTORE_ENV="${FILESTORE_ENV:-dev}"

export ANSIBLE_HOST_KEY_CHECKING=False

REPO_URL="https://harness:${GIT_TOKEN}@gitlab.onefiserv.net/latam/latam/merchant-latam/LAC/aws-cd-configuration/elastic-compute-cloud-sitef.git"

WORKDIR="$(mktemp -d)"
trap 'rm -rf "$WORKDIR"' EXIT

echo "Clonando repo em ${WORKDIR}..."
git clone --branch "${GIT_BRANCH}" "${REPO_URL}" "${WORKDIR}/elastic-compute-cloud-sitef"
cd "${WORKDIR}/elastic-compute-cloud-sitef"
git fetch --tags --force

echo "== PIPELINE PREDEPLOY =="
echo "TAG   : ${GIT_TAG}"
echo "EXEC  : ${EXECUTION_FILE_NAME}"
echo "BRANCH: ${GIT_BRANCH}"
echo

cd ansible

# Passa secrets via env (melhor do que -e)
export NEXUS_BASE_URL NEXUS_USER NEXUS_PASSWORD FILESTORE_ENV

ansible-playbook predeploy_from_execution.yml \
  -e "execution_file_name=${EXECUTION_FILE_NAME}" \
  -e "deployment_ref=${GIT_TAG}" \
  -e "nexus_base_url=${NEXUS_BASE_URL}" \
  -e "nexus_user=${NEXUS_USER}" \
  -e "nexus_password=${NEXUS_PASSWORD}" \
  -e "filestore_env=${FILESTORE_ENV}" \
  -e "stage_name=predeploy" \
  -e "harness_x_api_key=${HARNESS_X_API_KEY}" \
  --forks 10

segue script do harness
---
# =====================================================================================
# HARNESS FILESTORE UPLOAD (SEM RECURSÃO)
#
# Espera receber (via include_tasks vars):
# - log_content (string)
# - machine_status_file (path local controller)
# - stage_name (opcional, default: predeploy)
# - current_machine (string)  <-- NÃO será redefinido aqui
# - deployment_ref
# - filestore_env
# - filestore_base_dir
# - filestore_log_path (opcional)
# - filestore_status_path (opcional)
# - status_tag_value (string)
# - extra_tags (list)
#
# Credenciais (preferência vars Ansible; fallback env):
# - harness_endpoint / HARNESS_ENDPOINT (ex: https://harness.onefiserv.net)
# - harness_account_id / HARNESS_ACCOUNT_ID
# - harness_org_id / HARNESS_ORG_ID
# - harness_project_id / HARNESS_PROJECT_ID
# - harness_api_key / HARNESS_API_KEY   (PAT)
# =====================================================================================

# -----------------------------------------------------------------------------
# 1) Resolver entradas sem tocar no current_machine (evita recursão)
# -----------------------------------------------------------------------------
- name: "Harness | Resolver entradas (safe locals)"
  ansible.builtin.set_fact:
    hf_stage_name_resolved: "{{ hf_stage_name | default('unknown') }}"
    hf_machine: "{{ (current_machine | default(machine_name | default(''))) | string | trim }}"
    hf_deployment_ref: "{{ (deployment_ref | default(lookup('env','GIT_TAG') | default(''))) | string | trim }}"
    hf_env: "{{ (filestore_env | default('dev')) | string | trim | lower }}"
    hf_base_dir: "{{ (filestore_base_dir | default((filestore_env | default('dev')) ~ '/' ~ (deployment_ref | default('')))) | string | trim }}"
    hf_endpoint: "{{ (harness_endpoint | default(lookup('env','HARNESS_ENDPOINT') | default('https://harness.onefiserv.net'))) | string | trim }}"
    hf_account: "{{ (harness_account_id | default(lookup('env','HARNESS_ACCOUNT_ID') | default('fgDto6qoTT6ctfZS9eWbEw'))) | string | trim }}"
    hf_org: "{{ (harness_org_id | default(lookup('env','HARNESS_ORG_ID') | default('Fiserv'))) | string | trim }}"
    hf_project: "{{ (harness_project_id | default(lookup('env','HARNESS_PROJECT_ID') | default('sitef'))) | string | trim }}"
    hf_pat: "{{ (harness_api_key | default(lookup('env','HARNESS_API_KEY') | default('pat.fgDto6qoTT6ctfZS9eWbEw.693f147c43bfca2e849b46f4.WtMpaUZG5pxwDZcIkzl0'))) | string | trim }}"

- name: "Harness | Validar mínimos (sem falhar a pipeline)"
  ansible.builtin.debug:
    msg:
      - "hf_endpoint={{ hf_endpoint }}"
      - "hf_account={{ hf_account }}"
      - "hf_org={{ hf_org }}"
      - "hf_project={{ hf_project }}"
      - "hf_deployment_ref={{ hf_deployment_ref }}"
      - "hf_machine={{ hf_machine }}"
      - "hf_stage={{ hf_stage_name_resolved }}"
      - "hf_env={{ hf_env }}"
  changed_when: false

- name: "Harness | Pular upload se faltar credenciais do Harness"
  ansible.builtin.debug:
    msg: "Harness creds ausentes (HARNESS_API_KEY/HARNESS_ACCOUNT_ID/HARNESS_ORG_ID/HARNESS_PROJECT_ID). Pulando upload."
  when:
    - hf_pat | length == 0 or hf_account | length == 0 or hf_org | length == 0 or hf_project | length == 0
  changed_when: false

# -----------------------------------------------------------------------------
# 2) Construir nomes seguros para os arquivos
# -----------------------------------------------------------------------------
- name: "Harness | Resolver paths lógicos (fallback) + nomes safe"
  ansible.builtin.set_fact:
    hf_log_path: >-
      {{
        filestore_log_path
          | default(hf_base_dir ~ '/' ~ (hf_deployment_ref | lower) ~ '-' ~ (hf_machine | lower) ~ '-' ~ hf_env ~ '-' ~ hf_stage_name_resolved ~ '.log')
      }}
    hf_status_path: >-
      {{
        filestore_status_path
          | default(hf_base_dir ~ '/' ~ (hf_deployment_ref | lower) ~ '-' ~ (hf_machine | lower) ~ '-' ~ hf_env ~ '-' ~ hf_stage_name_resolved ~ '.json')
      }}
    hf_log_name: "{{ (hf_log_path | regex_replace('^/+','')) | replace('/','__') }}"
    hf_status_name: "{{ (hf_status_path | regex_replace('^/+','')) | replace('/','__') }}"
  when:
    - hf_pat | length > 0
    - hf_account | length > 0
    - hf_org | length > 0
    - hf_project | length > 0

# -----------------------------------------------------------------------------
# 3) Tags (string única)
# -----------------------------------------------------------------------------
- name: "Harness | Montar tags"
  ansible.builtin.set_fact:
    hf_tags_list: >-
      {{
        (
          [ status_tag_value | default('') ]
          + (extra_tags | default([]))
          + [
              (hf_deployment_ref | lower) ~ ':stage:' ~ hf_stage_name_resolved,
              (hf_deployment_ref | lower) ~ ':machine:' ~ (hf_machine | lower),
              (hf_deployment_ref | lower) ~ ':env:' ~ hf_env
            ]
        )
        | map('string')
        | map('trim')
        | reject('equalto','')
        | list
        | unique
      }}
    hf_tags: "{{ hf_tags_list | join(',') }}"
  when:
    - hf_pat | length > 0
    - hf_account | length > 0
    - hf_org | length > 0
    - hf_project | length > 0

# -----------------------------------------------------------------------------
# 4) Criar arquivos temporários (controller)
# -----------------------------------------------------------------------------
- name: "Harness | Criar temp dir (controller)"
  ansible.builtin.tempfile:
    state: directory
    suffix: hf_upload
  register: hf_tmpdir
  when:
    - hf_pat | length > 0
    - hf_account | length > 0
    - hf_org | length > 0
    - hf_project | length > 0

- name: "Harness | Escrever LOG temp (controller)"
  ansible.builtin.copy:
    dest: "{{ hf_tmpdir.path }}/{{ hf_log_name }}"
    mode: "0644"
    content: "{{ log_content | default('') }}"
  when: hf_tmpdir is defined

- name: "Harness | Ler status.json (controller)"
  ansible.builtin.slurp:
    path: "{{ machine_status_file }}"
  register: hf_status_slurp
  when:
    - hf_tmpdir is defined
    - machine_status_file is defined

- name: "Harness | Escrever STATUS temp (controller)"
  ansible.builtin.copy:
    dest: "{{ hf_tmpdir.path }}/{{ hf_status_name }}"
    mode: "0644"
    content: "{{ (hf_status_slurp.content | b64decode) if (hf_status_slurp is defined and hf_status_slurp.content is defined) else '{}' }}"
  when: hf_tmpdir is defined

# -----------------------------------------------------------------------------
# 5) Upload LOG e STATUS (NÃO falha pipeline se Harness der erro)
# -----------------------------------------------------------------------------
- name: "Harness | Upload LOG"
  ansible.builtin.shell: |
    set -euo pipefail
    API="{{ hf_endpoint.rstrip('/') }}/ng/api/file-store?accountIdentifier={{ hf_account }}&orgIdentifier={{ hf_org }}&projectIdentifier={{ hf_project }}"
    FILE="{{ hf_tmpdir.path }}/{{ hf_log_name }}"
    RESP="{{ hf_tmpdir.path }}/resp_log.json"

    code=$(curl -sS -o "$RESP" -w "%{http_code}" -X POST "$API" \
      -H "x-api-key: {{ hf_pat }}" \
      -F "parentIdentifier=Root" \
      -F "name={{ hf_log_name }}" \
      -F "type=FILE" \
      -F "tags={{ hf_tags }}" \
      -F "file=@${FILE};type=text/plain" \
    || true)

    echo "HTTP_CODE=${code}"
    echo "RESPONSE=$(cat "$RESP" 2>/dev/null || true)"
    # nunca falha por upload
    exit 0
  args:
    executable: /bin/bash
  register: hf_upload_log
  changed_when: false
  failed_when: false
  when: hf_tmpdir is defined

- name: "Harness | Upload STATUS"
  ansible.builtin.shell: |
    set -euo pipefail
    API="{{ hf_endpoint.rstrip('/') }}/ng/api/file-store?accountIdentifier={{ hf_account }}&orgIdentifier={{ hf_org }}&projectIdentifier={{ hf_project }}"
    FILE="{{ hf_tmpdir.path }}/{{ hf_status_name }}"
    RESP="{{ hf_tmpdir.path }}/resp_status.json"

    code=$(curl -sS -o "$RESP" -w "%{http_code}" -X POST "$API" \
      -H "x-api-key: {{ hf_pat }}" \
      -F "parentIdentifier=Root" \
      -F "name={{ hf_status_name }}" \
      -F "type=FILE" \
      -F "tags={{ hf_tags }}" \
      -F "file=@${FILE};type=application/json" \
    || true)

    echo "HTTP_CODE=${code}"
    echo "RESPONSE=$(cat "$RESP" 2>/dev/null || true)"
    # nunca falha por upload
    exit 0
  args:
    executable: /bin/bash
  register: hf_upload_status
  changed_when: false
  failed_when: false
  when: hf_tmpdir is defined

- name: "Harness | Resultado upload (debug)"
  ansible.builtin.debug:
    msg:
      - "upload_log: {{ (hf_upload_log.stdout_lines | default([])) }}"
      - "upload_status: {{ (hf_upload_status.stdout_lines | default([])) }}"
  changed_when: false
  when: hf_tmpdir is defined
