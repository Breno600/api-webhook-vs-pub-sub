segue log completo

Exec using JSCH
Connecting to 10.218.238.144 ....
Connection to 10.218.238.144 established
Executing command ...
export GIT_TAG=dev000006
Clonando repo em /tmp/tmp.eOyNFMWWgL...
Cloning into '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef'...
remote: Enumerating objects: 965, done.
remote: Counting objects:   0% (1/915)
remote: Counting objects:   1% (10/915)
remote: Counting objects:   2% (19/915)
remote: Counting objects:   3% (28/915)
remote: Counting objects:   4% (37/915)
remote: Counting objects:   5% (46/915)
remote: Counting objects:   6% (55/915)
remote: Counting objects:   7% (65/915)
remote: Counting objects:   8% (74/915)
remote: Counting objects:   9% (83/915)
remote: Counting objects:  10% (92/915)
remote: Counting objects:  11% (101/915)
remote: Counting objects:  12% (110/915)
remote: Counting objects:  13% (119/915)
remote: Counting objects:  14% (129/915)
remote: Counting objects:  15% (138/915)
remote: Counting objects:  16% (147/915)
remote: Counting objects:  17% (156/915)
remote: Counting objects:  18% (165/915)
remote: Counting objects:  19% (174/915)
remote: Counting objects:  20% (183/915)
remote: Counting objects:  21% (193/915)
remote: Counting objects:  22% (202/915)
remote: Counting objects:  23% (211/915)
remote: Counting objects:  24% (220/915)
remote: Counting objects:  25% (229/915)
remote: Counting objects:  26% (238/915)
remote: Counting objects:  27% (248/915)
remote: Counting objects:  28% (257/915)
remote: Counting objects:  29% (266/915)
remote: Counting objects:  30% (275/915)
remote: Counting objects:  31% (284/915)
remote: Counting objects:  32% (293/915)
remote: Counting objects:  33% (302/915)
remote: Counting objects:  34% (312/915)
remote: Counting objects:  35% (321/915)
remote: Counting objects:  36% (330/915)
remote: Counting objects:  37% (339/915)
remote: Counting objects:  38% (348/915)
remote: Counting objects:  39% (357/915)
remote: Counting objects:  40% (366/915)
remote: Counting objects:  41% (376/915)
remote: Counting objects:  42% (385/915)
remote: Counting objects:  43% (394/915)
remote: Counting objects:  44% (403/915)
remote: Counting objects:  45% (412/915)
remote: Counting objects:  46% (421/915)
remote: Counting objects:  47% (431/915)
remote: Counting objects:  48% (440/915)
remote: Counting objects:  49% (449/915)
remote: Counting objects:  50% (458/915)
remote: Counting objects:  51% (467/915)
remote: Counting objects:  52% (476/915)
remote: Counting objects:  53% (485/915)
remote: Counting objects:  54% (495/915)
remote: Counting objects:  55% (504/915)
remote: Counting objects:  56% (513/915)
remote: Counting objects:  57% (522/915)
remote: Counting objects:  58% (531/915)
remote: Counting objects:  59% (540/915)
remote: Counting objects:  60% (549/915)
remote: Counting objects:  61% (559/915)
remote: Counting objects:  62% (568/915)
remote: Counting objects:  63% (577/915)
remote: Counting objects:  64% (586/915)
remote: Counting objects:  65% (595/915)
remote: Counting objects:  66% (604/915)
remote: Counting objects:  67% (614/915)
remote: Counting objects:  68% (623/915)
remote: Counting objects:  69% (632/915)
remote: Counting objects:  70% (641/915)
remote: Counting objects:  71% (650/915)
remote: Counting objects:  72% (659/915)
remote: Counting objects:  73% (668/915)
remote: Counting objects:  74% (678/915)
remote: Counting objects:  75% (687/915)
remote: Counting objects:  76% (696/915)
remote: Counting objects:  77% (705/915)
remote: Counting objects:  78% (714/915)
remote: Counting objects:  79% (723/915)
remote: Counting objects:  80% (732/915)
remote: Counting objects:  81% (742/915)
remote: Counting objects:  82% (751/915)
remote: Counting objects:  83% (760/915)
remote: Counting objects:  84% (769/915)
remote: Counting objects:  85% (778/915)
remote: Counting objects:  86% (787/915)
remote: Counting objects:  87% (797/915)
remote: Counting objects:  88% (806/915)
remote: Counting objects:  89% (815/915)
remote: Counting objects:  90% (824/915)
remote: Counting objects:  91% (833/915)
remote: Counting objects:  92% (842/915)
remote: Counting objects:  93% (851/915)
remote: Counting objects:  94% (861/915)
remote: Counting objects:  95% (870/915)
remote: Counting objects:  96% (879/915)
remote: Counting objects:  97% (888/915)
remote: Counting objects:  98% (897/915)
remote: Counting objects:  99% (906/915)
remote: Counting objects: 100% (915/915)
remote: Counting objects: 100% (915/915), done.
remote: Compressing objects:   0% (1/900)
remote: Compressing objects:   1% (9/900)
remote: Compressing objects:   2% (18/900)
remote: Compressing objects:   3% (27/900)
remote: Compressing objects:   4% (36/900)
remote: Compressing objects:   5% (45/900)
remote: Compressing objects:   6% (54/900)
remote: Compressing objects:   7% (63/900)
remote: Compressing objects:   8% (72/900)
remote: Compressing objects:   9% (81/900)
remote: Compressing objects:  10% (90/900)
remote: Compressing objects:  11% (99/900)
remote: Compressing objects:  12% (108/900)
remote: Compressing objects:  13% (117/900)
remote: Compressing objects:  14% (126/900)
remote: Compressing objects:  15% (135/900)
remote: Compressing objects:  16% (144/900)
remote: Compressing objects:  17% (153/900)
remote: Compressing objects:  18% (162/900)
remote: Compressing objects:  19% (171/900)
remote: Compressing objects:  20% (180/900)
remote: Compressing objects:  21% (189/900)
remote: Compressing objects:  22% (198/900)
remote: Compressing objects:  23% (207/900)
remote: Compressing objects:  24% (216/900)
remote: Compressing objects:  25% (225/900)
remote: Compressing objects:  26% (234/900)
remote: Compressing objects:  27% (243/900)
remote: Compressing objects:  28% (252/900)
remote: Compressing objects:  29% (261/900)
remote: Compressing objects:  30% (270/900)
remote: Compressing objects:  31% (279/900)
remote: Compressing objects:  32% (288/900)
remote: Compressing objects:  33% (297/900)
remote: Compressing objects:  34% (306/900)
remote: Compressing objects:  35% (315/900)
remote: Compressing objects:  36% (324/900)
remote: Compressing objects:  37% (333/900)
remote: Compressing objects:  38% (342/900)
remote: Compressing objects:  39% (351/900)
remote: Compressing objects:  40% (360/900)
remote: Compressing objects:  41% (369/900)
remote: Compressing objects:  42% (378/900)
remote: Compressing objects:  43% (387/900)
remote: Compressing objects:  44% (396/900)
remote: Compressing objects:  45% (405/900)
remote: Compressing objects:  46% (414/900)
remote: Compressing objects:  47% (423/900)
remote: Compressing objects:  48% (432/900)
remote: Compressing objects:  49% (441/900)
remote: Compressing objects:  50% (450/900)
remote: Compressing objects:  51% (459/900)
remote: Compressing objects:  52% (468/900)
remote: Compressing objects:  53% (477/900)
remote: Compressing objects:  54% (486/900)
remote: Compressing objects:  55% (495/900)
remote: Compressing objects:  56% (504/900)
remote: Compressing objects:  57% (513/900)
remote: Compressing objects:  58% (522/900)
remote: Compressing objects:  59% (531/900)
remote: Compressing objects:  60% (540/900)
remote: Compressing objects:  61% (549/900)
remote: Compressing objects:  62% (558/900)
remote: Compressing objects:  63% (567/900)
remote: Compressing objects:  64% (576/900)
remote: Compressing objects:  65% (585/900)
remote: Compressing objects:  66% (594/900)
remote: Compressing objects:  67% (603/900)
remote: Compressing objects:  68% (612/900)
remote: Compressing objects:  69% (621/900)
remote: Compressing objects:  70% (630/900)
remote: Compressing objects:  71% (639/900)
remote: Compressing objects:  72% (648/900)
remote: Compressing objects:  73% (657/900)
remote: Compressing objects:  74% (666/900)
remote: Compressing objects:  75% (675/900)
remote: Compressing objects:  76% (684/900)
remote: Compressing objects:  77% (693/900)
remote: Compressing objects:  78% (702/900)
remote: Compressing objects:  79% (711/900)
remote: Compressing objects:  80% (720/900)
remote: Compressing objects:  81% (729/900)
remote: Compressing objects:  82% (738/900)
remote: Compressing objects:  83% (747/900)
remote: Compressing objects:  84% (756/900)
remote: Compressing objects:  85% (765/900)
remote: Compressing objects:  86% (774/900)
remote: Compressing objects:  87% (783/900)
remote: Compressing objects:  88% (792/900)
remote: Compressing objects:  89% (801/900)
remote: Compressing objects:  90% (810/900)
remote: Compressing objects:  91% (819/900)
remote: Compressing objects:  92% (828/900)
remote: Compressing objects:  93% (837/900)
remote: Compressing objects:  94% (846/900)
remote: Compressing objects:  95% (855/900)
remote: Compressing objects:  96% (864/900)
remote: Compressing objects:  97% (873/900)
remote: Compressing objects:  98% (882/900)
remote: Compressing objects:  99% (891/900)
remote: Compressing objects: 100% (900/900)
remote: Compressing objects: 100% (900/900), done.
Receiving objects:   0% (1/965)
Receiving objects:   1% (10/965)
Receiving objects:   2% (20/965)
Receiving objects:   3% (29/965)
Receiving objects:   4% (39/965)
Receiving objects:   5% (49/965)
Receiving objects:   6% (58/965)
Receiving objects:   7% (68/965)
Receiving objects:   8% (78/965)
Receiving objects:   9% (87/965)
Receiving objects:  10% (97/965)
Receiving objects:  11% (107/965)
Receiving objects:  12% (116/965)
Receiving objects:  13% (126/965)
Receiving objects:  14% (136/965)
Receiving objects:  15% (145/965)
Receiving objects:  16% (155/965)
Receiving objects:  17% (165/965)
Receiving objects:  18% (174/965)
Receiving objects:  19% (184/965)
Receiving objects:  20% (193/965)
Receiving objects:  21% (203/965)
Receiving objects:  22% (213/965)
Receiving objects:  23% (222/965)
Receiving objects:  24% (232/965)
Receiving objects:  25% (242/965)
Receiving objects:  26% (251/965)
Receiving objects:  27% (261/965)
Receiving objects:  28% (271/965)
Receiving objects:  29% (280/965)
Receiving objects:  30% (290/965)
Receiving objects:  31% (300/965)
Receiving objects:  32% (309/965)
Receiving objects:  33% (319/965)
Receiving objects:  34% (329/965)
Receiving objects:  35% (338/965)
Receiving objects:  36% (348/965)
Receiving objects:  37% (358/965)
Receiving objects:  38% (367/965)
Receiving objects:  39% (377/965)
Receiving objects:  40% (386/965)
Receiving objects:  41% (396/965)
Receiving objects:  42% (406/965)
Receiving objects:  43% (415/965)
Receiving objects:  44% (425/965)
Receiving objects:  45% (435/965)
Receiving objects:  46% (444/965)
Receiving objects:  47% (454/965)
Receiving objects:  48% (464/965)
Receiving objects:  49% (473/965)
Receiving objects:  50% (483/965)
Receiving objects:  51% (493/965)
Receiving objects:  52% (502/965)
Receiving objects:  53% (512/965)
Receiving objects:  54% (522/965)
Receiving objects:  55% (531/965)
Receiving objects:  56% (541/965)
Receiving objects:  57% (551/965)
Receiving objects:  58% (560/965)
Receiving objects:  59% (570/965)
Receiving objects:  60% (579/965)
Receiving objects:  61% (589/965)
Receiving objects:  62% (599/965)
Receiving objects:  63% (608/965)
Receiving objects:  64% (618/965)
Receiving objects:  65% (628/965)
Receiving objects:  66% (637/965)
Receiving objects:  67% (647/965)
Receiving objects:  68% (657/965)
Receiving objects:  69% (666/965)
Receiving objects:  70% (676/965)
Receiving objects:  71% (686/965)
Receiving objects:  72% (695/965)
Receiving objects:  73% (705/965)
Receiving objects:  74% (715/965)
Receiving objects:  75% (724/965)
Receiving objects:  76% (734/965)
Receiving objects:  77% (744/965)
Receiving objects:  78% (753/965)
Receiving objects:  79% (763/965)
Receiving objects:  80% (772/965)
Receiving objects:  81% (782/965)
Receiving objects:  82% (792/965)
Receiving objects:  83% (801/965)
remote: Total 965 (delta 627), reused 0 (delta 0), pack-reused 50
Receiving objects:  84% (811/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  85% (821/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  86% (830/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  87% (840/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  88% (850/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  89% (859/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  90% (869/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  91% (879/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  92% (888/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  93% (898/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  94% (908/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  95% (917/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  96% (927/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  97% (937/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  98% (946/965), 707.77 KiB | 1.35 MiB/s
Receiving objects:  99% (956/965), 707.77 KiB | 1.35 MiB/s
Receiving objects: 100% (965/965), 707.77 KiB | 1.35 MiB/s
Receiving objects: 100% (965/965), 949.96 KiB | 1.80 MiB/s, done.
Resolving deltas:   0% (0/646)
Resolving deltas:   1% (7/646)
Resolving deltas:   2% (13/646)
Resolving deltas:   3% (20/646)
Resolving deltas:   4% (26/646)
Resolving deltas:   5% (33/646)
Resolving deltas:   6% (39/646)
Resolving deltas:   7% (46/646)
Resolving deltas:   8% (52/646)
Resolving deltas:   9% (59/646)
Resolving deltas:  10% (65/646)
Resolving deltas:  11% (72/646)
Resolving deltas:  12% (78/646)
Resolving deltas:  13% (84/646)
Resolving deltas:  14% (91/646)
Resolving deltas:  15% (97/646)
Resolving deltas:  16% (104/646)
Resolving deltas:  17% (110/646)
Resolving deltas:  18% (118/646)
Resolving deltas:  19% (123/646)
Resolving deltas:  20% (130/646)
Resolving deltas:  21% (136/646)
Resolving deltas:  22% (143/646)
Resolving deltas:  23% (149/646)
Resolving deltas:  24% (156/646)
Resolving deltas:  25% (162/646)
Resolving deltas:  26% (168/646)
Resolving deltas:  27% (175/646)
Resolving deltas:  28% (181/646)
Resolving deltas:  29% (188/646)
Resolving deltas:  30% (194/646)
Resolving deltas:  31% (201/646)
Resolving deltas:  32% (207/646)
Resolving deltas:  33% (214/646)
Resolving deltas:  34% (220/646)
Resolving deltas:  35% (227/646)
Resolving deltas:  36% (233/646)
Resolving deltas:  37% (240/646)
Resolving deltas:  38% (246/646)
Resolving deltas:  39% (252/646)
Resolving deltas:  40% (259/646)
Resolving deltas:  41% (265/646)
Resolving deltas:  42% (272/646)
Resolving deltas:  43% (278/646)
Resolving deltas:  44% (285/646)
Resolving deltas:  45% (291/646)
Resolving deltas:  46% (298/646)
Resolving deltas:  47% (304/646)
Resolving deltas:  48% (311/646)
Resolving deltas:  49% (317/646)
Resolving deltas:  50% (323/646)
Resolving deltas:  51% (330/646)
Resolving deltas:  52% (336/646)
Resolving deltas:  53% (343/646)
Resolving deltas:  54% (349/646)
Resolving deltas:  55% (356/646)
Resolving deltas:  56% (362/646)
Resolving deltas:  57% (369/646)
Resolving deltas:  58% (375/646)
Resolving deltas:  59% (382/646)
Resolving deltas:  60% (388/646)
Resolving deltas:  61% (395/646)
Resolving deltas:  62% (401/646)
Resolving deltas:  63% (407/646)
Resolving deltas:  64% (414/646)
Resolving deltas:  65% (420/646)
Resolving deltas:  66% (427/646)
Resolving deltas:  67% (433/646)
Resolving deltas:  68% (440/646)
Resolving deltas:  69% (446/646)
Resolving deltas:  70% (453/646)
Resolving deltas:  71% (459/646)
Resolving deltas:  72% (466/646)
Resolving deltas:  73% (472/646)
Resolving deltas:  74% (479/646)
Resolving deltas:  75% (485/646)
Resolving deltas:  76% (491/646)
Resolving deltas:  77% (498/646)
Resolving deltas:  78% (504/646)
Resolving deltas:  79% (511/646)
Resolving deltas:  80% (517/646)
Resolving deltas:  81% (524/646)
Resolving deltas:  82% (530/646)
Resolving deltas:  83% (537/646)
Resolving deltas:  84% (543/646)
Resolving deltas:  85% (550/646)
Resolving deltas:  86% (556/646)
Resolving deltas:  87% (563/646)
Resolving deltas:  88% (569/646)
Resolving deltas:  89% (575/646)
Resolving deltas:  90% (582/646)
Resolving deltas:  91% (588/646)
Resolving deltas:  92% (595/646)
Resolving deltas:  93% (601/646)
Resolving deltas:  94% (608/646)
Resolving deltas:  95% (614/646)
Resolving deltas:  96% (621/646)
Resolving deltas:  97% (627/646)
Resolving deltas:  98% (634/646)
Resolving deltas:  99% (640/646)
Resolving deltas: 100% (646/646)
Resolving deltas: 100% (646/646), done.
== PIPELINE PREDEPLOY ==
TAG   : dev000006
EXEC  : execution/machine_list_dev.yml
BRANCH: develop-testes
[WARNING]: Unable to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/localhost as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/deploy_from_status.yml with auto plugin: no root 'plugin' key
found, '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/deploy_from_status.yml' is not a valid YAML inventory plugin
config file
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/deploy_from_status.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/deploy_from_status.yml with ini plugin: Invalid host pattern
'---' supplied, '---' is normally a sign this is a YAML file.
[WARNING]: Unable to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/deploy_from_status.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/deploy_per_machine.yml with auto plugin: no root 'plugin' key
found, '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/deploy_per_machine.yml' is not a valid YAML inventory plugin
config file
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/deploy_per_machine.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/deploy_per_machine.yml with ini plugin: Invalid host pattern
'---' supplied, '---' is normally a sign this is a YAML file.
[WARNING]: Unable to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/deploy_per_machine.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/harness_filestore_upload.yml with auto plugin: no root 'plugin'
key found, '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/harness_filestore_upload.yml' is not a valid YAML inventory
plugin config file
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/harness_filestore_upload.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/harness_filestore_upload.yml with ini plugin: Invalid host
pattern '---' supplied, '---' is normally a sign this is a YAML file.
[WARNING]: Unable to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/harness_filestore_upload.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml with auto plugin: no root 'plugin'
key found, '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml' is not a valid YAML inventory
plugin config file
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml with ini plugin:
/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml:5: Expected key=value host variable
assignment, got: name:
[WARNING]: Unable to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_from_execution.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_per_machine.yml with auto plugin: no root 'plugin' key
found, '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_per_machine.yml' is not a valid YAML inventory plugin
config file
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_per_machine.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_per_machine.yml with ini plugin: Invalid host pattern
'---' supplied, '---' is normally a sign this is a YAML file.
[WARNING]: Unable to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/predeploy_per_machine.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml with auto plugin: no root 'plugin' key
found, '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml' is not a valid YAML inventory plugin
config file
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml with ini plugin:
/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml:5: Expected key=value host variable
assignment, got: name:
[WARNING]: Unable to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_from_status.yml as an inventory source
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_per_machine.yml with auto plugin: no root 'plugin' key
found, '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_per_machine.yml' is not a valid YAML inventory plugin
config file
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_per_machine.yml with yaml plugin: YAML inventory has
invalid structure, it should be a dictionary, got: &lt;class
'ansible.parsing.yaml.objects.AnsibleSequence'>
[WARNING]:  * Failed to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_per_machine.yml with ini plugin: Invalid host pattern
'---' supplied, '---' is normally a sign this is a YAML file.
[WARNING]: Unable to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible/rollback_per_machine.yml as an inventory source
[WARNING]: Unable to parse /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-
sitef/ansible as an inventory source
[WARNING]: No inventory was parsed, only implicit localhost is available
[WARNING]: provided hosts list is empty, only localhost is available. Note that
the implicit localhost does not match 'all'
PLAY [Predeploy a partir do arquivo de execução] *******************************
TASK [Gathering Facts] *********************************************************
ok: [localhost]
TASK [Resolver filestore_env e filestore_base_dir sem recursão] ****************
ok: [localhost]
TASK [Mostrar variáveis de entrada e resolvidas] *******************************
ok: [localhost] => {
    "msg": [
        "execution_file_name          = execution/machine_list_dev.yml",
        "deployment_ref               = dev000006",
        "repo_root_resolved           = /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/..",
        "status_dir_resolved          = /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../status/dev000006",
        "filestore_env_resolved       = dev",
        "filestore_base_dir_resolved  = dev/dev000006",
        "nexus_base_url               = https://nexus-ci.onefiserv.net/repository/raw-apm0004548-dev"
    ]
}
TASK [Criar diretório de status da TAG] ****************************************
changed: [localhost]
TASK [Carregar arquivo de execução] ********************************************
ok: [localhost]
TASK [Falhar se não tiver máquinas no arquivo de execução] *********************
skipping: [localhost]
TASK [Executar pré-deploy por máquina] *****************************************
included: /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/predeploy_per_machine.yml for localhost => (item=sitef-02)
TASK [Predeploy | Resolver nome da máquina atual] ******************************
ok: [localhost]
TASK [Predeploy | Validar vars mínimas] ****************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
TASK [Predeploy | Definir paths base do repositório] ***************************
ok: [localhost]
TASK [Predeploy | Definir candidatos de arquivo da máquina] ********************
ok: [localhost]
TASK [Predeploy | Verificar candidatos] ****************************************
ok: [localhost] => (item=/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../execution/machines/sitef-02.yml)
ok: [localhost] => (item=/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../execution/sitef-02.yml)
ok: [localhost] => (item=/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../machines/sitef-02.yml)
ok: [localhost] => (item=/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../inventory/machines/sitef-02.yml)
TASK [Predeploy | Selecionar machine_file existente] ***************************
skipping: [localhost] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../execution/machines/sitef-02.yml', 'follow': False, 'get_md5': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../execution/machines/sitef-02.yml', 'ansible_loop_var': 'item'}) 
skipping: [localhost] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../execution/sitef-02.yml', 'follow': False, 'get_md5': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../execution/sitef-02.yml', 'ansible_loop_var': 'item'}) 
ok: [localhost] => (item={'changed': False, 'stat': {'exists': True, 'path': '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../machines/sitef-02.yml', 'mode': '0640', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1000, 'gid': 1000, 'size': 248, 'inode': 6307342, 'dev': 64775, 'nlink': 1, 'atime': 1766604782.9476266, 'mtime': 1766604782.9386265, 'ctime': 1766604782.9386265, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'ec2-user', 'gr_name': 'ec2-user', 'checksum': '005e3367129d5aefc77f49fd9fe62b4e58c51cd5', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '1239692956', 'attributes': [], 'attr_flags': ''}, 'invocation': {'module_args': {'path': '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../machines/sitef-02.yml', 'follow': False, 'get_md5': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../machines/sitef-02.yml', 'ansible_loop_var': 'item'})
skipping: [localhost] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../inventory/machines/sitef-02.yml', 'follow': False, 'get_md5': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/../inventory/machines/sitef-02.yml', 'ansible_loop_var': 'item'}) 
TASK [Predeploy | Falhar se arquivo da máquina não existir] ********************
skipping: [localhost]
TASK [Predeploy | Carregar config da máquina sitef-02] *************************
ok: [localhost]
TASK [Predeploy | Validar package definido] ************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
TASK [Predeploy | Carregar config do pacote sitef-core-0.0.1-0] ****************
ok: [localhost]
TASK [Predeploy | Validar components do pacote] ********************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
TASK [Predeploy | Validar script do pacote] ************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
TASK [Predeploy | Definir usuário alvo padrão] *********************************
ok: [localhost]
TASK [Predeploy | Definir ssh_common_args padrão] ******************************
ok: [localhost]
TASK [Predeploy | Aplicar ProxyJump via bastion (quando necessário)] ***********
skipping: [localhost]
TASK [Predeploy | Registrar host dinâmico para sitef-02] ***********************
changed: [localhost]
TASK [Predeploy | Montar env final (package base + machine override)] **********
ok: [localhost]
TASK [Predeploy | Normalizações] ***********************************************
ok: [localhost]
TASK [Predeploy | Gerar run_id] ************************************************
ok: [localhost]
TASK [Predeploy | Definir arquivos/diretórios locais] **************************
ok: [localhost]
TASK [Predeploy | Definir paths lógicos (File Store) SEPARADOS POR STAGE] ******
ok: [localhost]
TASK [Predeploy | Garantir diretório de status local] **************************
changed: [localhost]
TASK [Predeploy | Garantir arquivo pipeline.log (cumulativo local)] ************
changed: [localhost]
TASK [Predeploy | Verificar se status.json já existe] **************************
ok: [localhost]
TASK [Predeploy | Ler status.json existente (se existir)] **********************
skipping: [localhost]
TASK [Predeploy | Parse do status existente (ou base vazio)] *******************
ok: [localhost]
TASK [Predeploy | Escrever status inicial (predeploy:queued) com history append] ***
changed: [localhost]
TASK [Predeploy | Definir diretórios remotos do pipeline] **********************
ok: [localhost]
TASK [Predeploy | Garantir base do pipeline no host] ***************************
ok: [localhost -> sitef-02(100.99.57.128)] => (item=/opt/SoftwareExpress/sitef-pipeline/deploy/components)
ok: [localhost -> sitef-02(100.99.57.128)] => (item=/opt/SoftwareExpress/sitef-pipeline/deploy/scripts)
ok: [localhost -> sitef-02(100.99.57.128)] => (item=/opt/SoftwareExpress/sitef-pipeline/deploy/scripts/package)
TASK [Predeploy | Limpar pasta de scripts do pacote] ***************************
changed: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Recriar pasta de scripts do pacote] **************************
changed: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Copiar package.yml para o host] ******************************
changed: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Garantir diretórios dos componentes no host] *****************
ok: [localhost -> sitef-02(100.99.57.128)] => (item=packages/linux/sitef-core-0.0.1-0.x86_64.rpm)
TASK [Predeploy | Baixar componentes do Nexus] *********************************
ok: [localhost -> sitef-02(100.99.57.128)] => (item=packages/linux/sitef-core-0.0.1-0.x86_64.rpm)
TASK [Predeploy | Copiar scripts do pacote para o host] ************************
ok: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Executar init_parallel.sh no host (com log + stdout)] ********
changed: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Tail do init_parallel.log (sempre)] **************************
ok: [localhost -> sitef-02(100.99.57.128)]
TASK [Predeploy | Montar conteúdo do log (bloco predeploy)] ********************
ok: [localhost]
TASK [Predeploy | Append do bloco no pipeline.log (controller)] ****************
changed: [localhost]
TASK [Predeploy | Carregar conteúdo completo do pipeline.log (controller)] *****
ok: [localhost]
TASK [Predeploy | Ler status.json atual] ***************************************
ok: [localhost]
TASK [Predeploy | Parse do status atual] ***************************************
ok: [localhost]
TASK [Predeploy | Atualizar status final (append em history)] ******************
changed: [localhost]
TASK [Predeploy | Upload JSON + LOG para Harness File Store (sempre)] **********
included: /tmp/tmp.eOyNFMWWgL/elastic-compute-cloud-sitef/ansible/harness_filestore_upload.yml for localhost
TASK [Harness | Resolver entradas (safe locals)] *******************************
fatal: [localhost]: FAILED! => {"msg": "An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ current_machine }}'. Error was a &lt;class 'ansible.errors.AnsibleError'>, original message: recursive loop detected in template string: {{ current_machine }}. maximum recursion depth exceeded while calling a Python object"}
PLAY RECAP *********************************************************************
localhost                  : ok=47   changed=11   unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
Command finished with status FAILURE


segue script atual do harness
---
# =====================================================================================
# HARNESS FILESTORE UPLOAD (SEM RECURSÃO)
#
# Espera receber (via include_tasks vars):
# - log_content (string)
# - machine_status_file (path local controller)
# - stage_name (opcional, default: predeploy)
# - current_machine (string)  <-- NÃO será redefinido aqui
# - deployment_ref
# - filestore_env
# - filestore_base_dir
# - filestore_log_path (opcional)
# - filestore_status_path (opcional)
# - status_tag_value (string)
# - extra_tags (list)
#
# Credenciais (preferência vars Ansible; fallback env):
# - harness_endpoint / HARNESS_ENDPOINT (ex: https://harness.onefiserv.net)
# - harness_account_id / HARNESS_ACCOUNT_ID
# - harness_org_id / HARNESS_ORG_ID
# - harness_project_id / HARNESS_PROJECT_ID
# - harness_api_key / HARNESS_API_KEY   (PAT)
# =====================================================================================

# -----------------------------------------------------------------------------
# 1) Resolver entradas sem tocar no current_machine (evita recursão)
# -----------------------------------------------------------------------------
- name: "Harness | Resolver entradas (safe locals)"
  ansible.builtin.set_fact:
    hf_stage_name_resolved: "{{ hf_stage_name | default('unknown') }}"
    hf_machine: "{{ (current_machine | default(machine_name | default(''))) | string | trim }}"
    hf_deployment_ref: "{{ (deployment_ref | default(lookup('env','GIT_TAG') | default(''))) | string | trim }}"
    hf_env: "{{ (filestore_env | default('dev')) | string | trim | lower }}"
    hf_base_dir: "{{ (filestore_base_dir | default((filestore_env | default('dev')) ~ '/' ~ (deployment_ref | default('')))) | string | trim }}"
    hf_endpoint: "{{ (harness_endpoint | default(lookup('env','HARNESS_ENDPOINT') | default('https://harness.onefiserv.net'))) | string | trim }}"
    hf_account: "{{ (harness_account_id | default(lookup('env','HARNESS_ACCOUNT_ID') | default(''))) | string | trim }}"
    hf_org: "{{ (harness_org_id | default(lookup('env','HARNESS_ORG_ID') | default(''))) | string | trim }}"
    hf_project: "{{ (harness_project_id | default(lookup('env','HARNESS_PROJECT_ID') | default(''))) | string | trim }}"
    hf_pat: "{{ (harness_api_key | default(lookup('env','HARNESS_API_KEY') | default(''))) | string | trim }}"

- name: "Harness | Validar mínimos (sem falhar a pipeline)"
  ansible.builtin.debug:
    msg:
      - "hf_endpoint={{ hf_endpoint }}"
      - "hf_account={{ hf_account }}"
      - "hf_org={{ hf_org }}"
      - "hf_project={{ hf_project }}"
      - "hf_deployment_ref={{ hf_deployment_ref }}"
      - "hf_machine={{ hf_machine }}"
      - "hf_stage={{ hf_stage_name_resolved }}"
      - "hf_env={{ hf_env }}"
  changed_when: false

- name: "Harness | Pular upload se faltar credenciais do Harness"
  ansible.builtin.debug:
    msg: "Harness creds ausentes (HARNESS_API_KEY/HARNESS_ACCOUNT_ID/HARNESS_ORG_ID/HARNESS_PROJECT_ID). Pulando upload."
  when:
    - hf_pat | length == 0 or hf_account | length == 0 or hf_org | length == 0 or hf_project | length == 0
  changed_when: false

# -----------------------------------------------------------------------------
# 2) Construir nomes seguros para os arquivos
# -----------------------------------------------------------------------------
- name: "Harness | Resolver paths lógicos (fallback) + nomes safe"
  ansible.builtin.set_fact:
    hf_log_path: >-
      {{
        filestore_log_path
          | default(hf_base_dir ~ '/' ~ (hf_deployment_ref | lower) ~ '-' ~ (hf_machine | lower) ~ '-' ~ hf_env ~ '-' ~ hf_stage_name_resolved ~ '.log')
      }}
    hf_status_path: >-
      {{
        filestore_status_path
          | default(hf_base_dir ~ '/' ~ (hf_deployment_ref | lower) ~ '-' ~ (hf_machine | lower) ~ '-' ~ hf_env ~ '-' ~ hf_stage_name_resolved ~ '.json')
      }}
    hf_log_name: "{{ (hf_log_path | regex_replace('^/+','')) | replace('/','__') }}"
    hf_status_name: "{{ (hf_status_path | regex_replace('^/+','')) | replace('/','__') }}"
  when:
    - hf_pat | length > 0
    - hf_account | length > 0
    - hf_org | length > 0
    - hf_project | length > 0

# -----------------------------------------------------------------------------
# 3) Tags (string única)
# -----------------------------------------------------------------------------
- name: "Harness | Montar tags"
  ansible.builtin.set_fact:
    hf_tags_list: >-
      {{
        (
          [ status_tag_value | default('') ]
          + (extra_tags | default([]))
          + [
              (hf_deployment_ref | lower) ~ ':stage:' ~ hf_stage_name_resolved,
              (hf_deployment_ref | lower) ~ ':machine:' ~ (hf_machine | lower),
              (hf_deployment_ref | lower) ~ ':env:' ~ hf_env
            ]
        )
        | map('string')
        | map('trim')
        | reject('equalto','')
        | list
        | unique
      }}
    hf_tags: "{{ hf_tags_list | join(',') }}"
  when:
    - hf_pat | length > 0
    - hf_account | length > 0
    - hf_org | length > 0
    - hf_project | length > 0

# -----------------------------------------------------------------------------
# 4) Criar arquivos temporários (controller)
# -----------------------------------------------------------------------------
- name: "Harness | Criar temp dir (controller)"
  ansible.builtin.tempfile:
    state: directory
    suffix: hf_upload
  register: hf_tmpdir
  when:
    - hf_pat | length > 0
    - hf_account | length > 0
    - hf_org | length > 0
    - hf_project | length > 0

- name: "Harness | Escrever LOG temp (controller)"
  ansible.builtin.copy:
    dest: "{{ hf_tmpdir.path }}/{{ hf_log_name }}"
    mode: "0644"
    content: "{{ log_content | default('') }}"
  when: hf_tmpdir is defined

- name: "Harness | Ler status.json (controller)"
  ansible.builtin.slurp:
    path: "{{ machine_status_file }}"
  register: hf_status_slurp
  when:
    - hf_tmpdir is defined
    - machine_status_file is defined

- name: "Harness | Escrever STATUS temp (controller)"
  ansible.builtin.copy:
    dest: "{{ hf_tmpdir.path }}/{{ hf_status_name }}"
    mode: "0644"
    content: "{{ (hf_status_slurp.content | b64decode) if (hf_status_slurp is defined and hf_status_slurp.content is defined) else '{}' }}"
  when: hf_tmpdir is defined

# -----------------------------------------------------------------------------
# 5) Upload LOG e STATUS (NÃO falha pipeline se Harness der erro)
# -----------------------------------------------------------------------------
- name: "Harness | Upload LOG"
  ansible.builtin.shell: |
    set -euo pipefail
    API="{{ hf_endpoint.rstrip('/') }}/ng/api/file-store?accountIdentifier={{ hf_account }}&orgIdentifier={{ hf_org }}&projectIdentifier={{ hf_project }}"
    FILE="{{ hf_tmpdir.path }}/{{ hf_log_name }}"
    RESP="{{ hf_tmpdir.path }}/resp_log.json"

    code=$(curl -sS -o "$RESP" -w "%{http_code}" -X POST "$API" \
      -H "x-api-key: {{ hf_pat }}" \
      -F "parentIdentifier=Root" \
      -F "name={{ hf_log_name }}" \
      -F "type=FILE" \
      -F "tags={{ hf_tags }}" \
      -F "file=@${FILE};type=text/plain" \
    || true)

    echo "HTTP_CODE=${code}"
    echo "RESPONSE=$(cat "$RESP" 2>/dev/null || true)"
    # nunca falha por upload
    exit 0
  args:
    executable: /bin/bash
  register: hf_upload_log
  changed_when: false
  failed_when: false
  when: hf_tmpdir is defined

- name: "Harness | Upload STATUS"
  ansible.builtin.shell: |
    set -euo pipefail
    API="{{ hf_endpoint.rstrip('/') }}/ng/api/file-store?accountIdentifier={{ hf_account }}&orgIdentifier={{ hf_org }}&projectIdentifier={{ hf_project }}"
    FILE="{{ hf_tmpdir.path }}/{{ hf_status_name }}"
    RESP="{{ hf_tmpdir.path }}/resp_status.json"

    code=$(curl -sS -o "$RESP" -w "%{http_code}" -X POST "$API" \
      -H "x-api-key: {{ hf_pat }}" \
      -F "parentIdentifier=Root" \
      -F "name={{ hf_status_name }}" \
      -F "type=FILE" \
      -F "tags={{ hf_tags }}" \
      -F "file=@${FILE};type=application/json" \
    || true)

    echo "HTTP_CODE=${code}"
    echo "RESPONSE=$(cat "$RESP" 2>/dev/null || true)"
    # nunca falha por upload
    exit 0
  args:
    executable: /bin/bash
  register: hf_upload_status
  changed_when: false
  failed_when: false
  when: hf_tmpdir is defined

- name: "Harness | Resultado upload (debug)"
  ansible.builtin.debug:
    msg:
      - "upload_log: {{ (hf_upload_log.stdout_lines | default([])) }}"
      - "upload_status: {{ (hf_upload_status.stdout_lines | default([])) }}"
  changed_when: false
  when: hf_tmpdir is defined


segue script atual do pre deploy
# =====================================================================================
# PIPELINE 1 - PREDEPLOY (a partir do arquivo de execução)
# =====================================================================================

- name: "Predeploy a partir do arquivo de execução"
  hosts: localhost
  connection: local
  gather_facts: true

  vars:
    # -------------------------------
    # Entradas principais
    # -------------------------------
    execution_file_name: "{{ execution_file_name | default('execution/machine_list_dev.yml') }}"
    deployment_ref: "{{ deployment_ref | default('DEV000000001') }}"

    # -------------------------------
    # Paths do repositório
    # -------------------------------
    repo_root_resolved: "{{ playbook_dir }}/.."
    status_dir_resolved: "{{ (playbook_dir ~ '/..') }}/status/{{ deployment_ref }}"

    # -------------------------------
    # Nexus (ideal vir de secrets do Harness)
    # -------------------------------
    nexus_base_url: "{{ nexus_base_url | default('https://nexus-ci.onefiserv.net/repository/raw-apm0004548-dev') }}"
    nexus_user: "{{ nexus_user | default(omit) }}"
    nexus_password: "{{ nexus_password | default(omit) }}"
    hf_stage_name: predeploy

  tasks:
    # ---------------------------------------
    # Resolver File Store sem recursão
    # ---------------------------------------
    - name: "Resolver filestore_env e filestore_base_dir sem recursão"
      ansible.builtin.set_fact:
        filestore_env_resolved: >-
          {{
            (filestore_env | string | trim)
              if (filestore_env is defined and (filestore_env | string | trim) | length > 0)
              else 'dev'
          }}
        filestore_base_dir_resolved: >-
          {{
            (filestore_base_dir | string | trim)
              if (filestore_base_dir is defined and (filestore_base_dir | string | trim) | length > 0)
              else (
                (
                  (filestore_env | string | trim)
                    if (filestore_env is defined and (filestore_env | string | trim) | length > 0)
                    else 'dev'
                ) ~ '/' ~ deployment_ref
              )
          }}

    # ---------------------------------------
    # Mostrar variáveis resolvidas (debug)
    # ---------------------------------------
    - name: "Mostrar variáveis de entrada e resolvidas"
      ansible.builtin.debug:
        msg:
          - "execution_file_name          = {{ execution_file_name }}"
          - "deployment_ref               = {{ deployment_ref }}"
          - "repo_root_resolved           = {{ repo_root_resolved }}"
          - "status_dir_resolved          = {{ status_dir_resolved }}"
          - "filestore_env_resolved       = {{ filestore_env_resolved }}"
          - "filestore_base_dir_resolved  = {{ filestore_base_dir_resolved }}"
          - "nexus_base_url               = {{ nexus_base_url }}"

    # ---------------------------------------
    # Criar diretório base de status local
    # ---------------------------------------
    - name: "Criar diretório de status da TAG"
      ansible.builtin.file:
        path: "{{ status_dir_resolved }}"
        state: directory
        mode: "0755"

    # ---------------------------------------
    # Carregar arquivo de execução
    # ---------------------------------------
    - name: "Carregar arquivo de execução"
      ansible.builtin.include_vars:
        file: "{{ repo_root_resolved }}/{{ execution_file_name }}"
        name: execution_cfg

    # ---------------------------------------
    # Validar se há máquinas
    # ---------------------------------------
    - name: "Falhar se não tiver máquinas no arquivo de execução"
      ansible.builtin.fail:
        msg: "Nenhuma máquina encontrada em execution_cfg.machines"
      when: execution_cfg.machines is not defined or execution_cfg.machines | length == 0

    # ---------------------------------------
    # Executar PREDEPLOY por máquina
    # ---------------------------------------
    - name: "Executar pré-deploy por máquina"
      ansible.builtin.include_tasks: predeploy_per_machine.yml
      loop: "{{ execution_cfg.machines }}"
      loop_control:
        loop_var: machine_name
      vars:
        deployment_ref: "{{ deployment_ref }}"
        repo_root: "{{ repo_root_resolved }}"
        status_dir: "{{ status_dir_resolved }}"

        nexus_base_url: "{{ nexus_base_url }}"
        nexus_user: "{{ nexus_user | default('') }}"
        nexus_password: "{{ nexus_password | default('') }}"

        filestore_env: "{{ filestore_env_resolved }}"
        filestore_base_dir: "{{ filestore_base_dir_resolved }}"

segue script completo do pre deploy

---
# =====================================================================================
# PREDEPLOY POR MÁQUINA (COMPLETO / CORRIGIDO)
# Chamado por: predeploy_from_execution.yml
#
# Fix principal:
# - NÃO referenciar deployment_ref_lower dentro do mesmo set_fact onde ele é criado.
# =====================================================================================

# -----------------------------------------------------------------------------
# 0) Resolver nome da máquina atual + stage
# -----------------------------------------------------------------------------
- name: "Predeploy | Resolver nome da máquina atual"
  ansible.builtin.set_fact:
    stage_name: "predeploy"
    current_machine: "{{ (machine_name | default(item) | default('')) | string | trim }}"

- name: "Predeploy | Validar vars mínimas"
  ansible.builtin.assert:
    that:
      - (current_machine | length) > 0
      - deployment_ref is defined
      - (deployment_ref | string | trim | length) > 0
      - filestore_env is defined
      - (filestore_env | string | trim | length) > 0
      - filestore_base_dir is defined
      - (filestore_base_dir | string | trim | length) > 0
      - status_dir is defined
      - (status_dir | string | trim | length) > 0
      - nexus_base_url is defined
      - (nexus_base_url | string | trim | length) > 0
    fail_msg: "Faltam variáveis obrigatórias para o predeploy_per_machine.yml"

# -----------------------------------------------------------------------------
# 1) Paths base do repositório
# -----------------------------------------------------------------------------
- name: "Predeploy | Definir paths base do repositório"
  ansible.builtin.set_fact:
    repo_root_safe: "{{ repo_root | default(repo_root_resolved | default(playbook_dir ~ '/..')) }}"
    execution_dir: "{{ (repo_root | default(repo_root_resolved | default(playbook_dir ~ '/..'))) }}/execution"
    machines_dir: "{{ (repo_root | default(repo_root_resolved | default(playbook_dir ~ '/..'))) }}/machines"
    packages_dir: "{{ (repo_root | default(repo_root_resolved | default(playbook_dir ~ '/..'))) }}/packages"
    scripts_root_dir: "{{ (repo_root | default(repo_root_resolved | default(playbook_dir ~ '/..'))) }}/scripts"

# -----------------------------------------------------------------------------
# 2) Resolver machine_file
# -----------------------------------------------------------------------------
- name: "Predeploy | Definir candidatos de arquivo da máquina"
  ansible.builtin.set_fact:
    candidate_machine_files:
      - "{{ execution_dir }}/machines/{{ current_machine }}.yml"
      - "{{ execution_dir }}/{{ current_machine }}.yml"
      - "{{ machines_dir }}/{{ current_machine }}.yml"
      - "{{ repo_root_safe }}/inventory/machines/{{ current_machine }}.yml"

- name: "Predeploy | Verificar candidatos"
  ansible.builtin.stat:
    path: "{{ item }}"
  loop: "{{ candidate_machine_files }}"
  register: machine_candidates_stat

- name: "Predeploy | Selecionar machine_file existente"
  ansible.builtin.set_fact:
    machine_file: "{{ item.item }}"
  when:
    - item.stat.exists
    - machine_file is not defined
  loop: "{{ machine_candidates_stat.results }}"

- name: "Predeploy | Falhar se arquivo da máquina não existir"
  ansible.builtin.fail:
    msg: |
      [predeploy] Arquivo de máquina não encontrado para {{ current_machine }}.
      Caminhos testados:
      {{ candidate_machine_files | to_nice_yaml }}
  when: machine_file is not defined

# -----------------------------------------------------------------------------
# 3) Carregar machine_cfg + package_cfg
# -----------------------------------------------------------------------------
- name: "Predeploy | Carregar config da máquina {{ current_machine }}"
  ansible.builtin.include_vars:
    file: "{{ machine_file }}"
    name: machine_cfg

- name: "Predeploy | Validar package definido"
  ansible.builtin.assert:
    that:
      - machine_cfg is defined
      - machine_cfg.package is defined
      - (machine_cfg.package | string | trim | length) > 0
    fail_msg: "machine_cfg.package não definido em {{ machine_file }}"

- name: "Predeploy | Carregar config do pacote {{ machine_cfg.package }}"
  ansible.builtin.include_vars:
    file: "{{ packages_dir }}/{{ machine_cfg.package }}.yml"
    name: package_cfg

- name: "Predeploy | Validar components do pacote"
  ansible.builtin.assert:
    that:
      - package_cfg is defined
      - package_cfg.components is defined
      - (package_cfg.components | length) > 0
    fail_msg: "components ausente/vazio no pacote {{ machine_cfg.package }}"

- name: "Predeploy | Validar script do pacote"
  ansible.builtin.assert:
    that:
      - package_cfg.script is defined
      - (package_cfg.script | string | trim | length) > 0
    fail_msg: "package_cfg.script ausente/vazio no pacote {{ machine_cfg.package }}"

# -----------------------------------------------------------------------------
# 4) SSH e host dinâmico
# -----------------------------------------------------------------------------
- name: "Predeploy | Definir usuário alvo padrão"
  ansible.builtin.set_fact:
    target_user: "{{ machine_cfg.user | default(machine_cfg.target_user | default('root')) }}"

- name: "Predeploy | Definir ssh_common_args padrão"
  ansible.builtin.set_fact:
    ssh_common_args: "{{ machine_cfg.ssh_common_args | default('-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null') }}"

- name: "Predeploy | Aplicar ProxyJump via bastion (quando necessário)"
  ansible.builtin.set_fact:
    ssh_common_args: >-
      {{ ssh_common_args }}
      -o ProxyJump={{ machine_cfg.bastion_user | default(target_user) }}@{{ machine_cfg.bastion_host }}
  when:
    - machine_cfg.bastion_host is defined
    - (machine_cfg.bastion_host | string | length) > 0

- name: "Predeploy | Registrar host dinâmico para {{ current_machine }}"
  ansible.builtin.add_host:
    name: "{{ current_machine }}"
    ansible_host: "{{ machine_cfg.host | default(machine_cfg.ip | default('')) }}"
    ansible_user: "{{ target_user }}"
    ansible_ssh_common_args: "{{ ssh_common_args }}"
    ansible_connection: ssh
  changed_when: true

# -----------------------------------------------------------------------------
# 5) Montar env final (package base + machine override) + extras
# -----------------------------------------------------------------------------
- name: "Predeploy | Montar env final (package base + machine override)"
  ansible.builtin.set_fact:
    merged_env_vars: >-
      {{
        (package_cfg.env_vars | default({}))
        | combine(machine_cfg.env_vars | default({}), recursive=True)
        | combine({
            'SITEF_MACHINE': current_machine,
            'SITEF_HOST': (machine_cfg.host | default(machine_cfg.ip | default(''))),
            'DEPLOYMENT_REF': (deployment_ref | default('')),
            'PACKAGE_NAME': (machine_cfg.package | default('')),
            'ROLLBACK_PACKAGE': (machine_cfg.rollback | default(''))
          }, recursive=True)
      }}

# -----------------------------------------------------------------------------
# 6) Normalizações + run_id  (FIX: split set_fact)
# -----------------------------------------------------------------------------
- name: "Predeploy | Normalizações"
  ansible.builtin.set_fact:
    deployment_ref_lower: "{{ (deployment_ref | string | trim | lower) }}"
    env_lower: "{{ (filestore_env | string | trim | lower) }}"
    machine_lower: "{{ (current_machine | string | trim | lower) }}"

- name: "Predeploy | Gerar run_id"
  ansible.builtin.set_fact:
    run_id: "{{ deployment_ref_lower ~ '-' ~ machine_lower ~ '-' ~ env_lower ~ '-' ~ stage_name ~ '-' ~ ansible_date_time.epoch }}"

# -----------------------------------------------------------------------------
# 7) Paths local (controller) + paths remotos do pipeline
# -----------------------------------------------------------------------------
- name: "Predeploy | Definir arquivos/diretórios locais"
  ansible.builtin.set_fact:
    machine_status_dir: "{{ status_dir }}/{{ current_machine }}"
    machine_status_file: "{{ status_dir }}/{{ current_machine }}/status.json"
    pipeline_log_file: "{{ status_dir }}/{{ current_machine }}/pipeline.log"

- name: "Predeploy | Definir paths lógicos (File Store) SEPARADOS POR STAGE"
  ansible.builtin.set_fact:
    filestore_log_path: "{{ filestore_base_dir }}/{{ deployment_ref_lower }}-{{ machine_lower }}-{{ env_lower }}-{{ stage_name }}.log"
    filestore_status_path: "{{ filestore_base_dir }}/{{ deployment_ref_lower }}-{{ machine_lower }}-{{ env_lower }}-{{ stage_name }}.json"

- name: "Predeploy | Garantir diretório de status local"
  ansible.builtin.file:
    path: "{{ machine_status_dir }}"
    state: directory
    mode: "0755"

- name: "Predeploy | Garantir arquivo pipeline.log (cumulativo local)"
  ansible.builtin.file:
    path: "{{ pipeline_log_file }}"
    state: touch
    mode: "0644"

# -----------------------------------------------------------------------------
# 8) Status.json com history (append) - queued
# -----------------------------------------------------------------------------
- name: "Predeploy | Verificar se status.json já existe"
  ansible.builtin.stat:
    path: "{{ machine_status_file }}"
  register: status_stat

- name: "Predeploy | Ler status.json existente (se existir)"
  ansible.builtin.slurp:
    path: "{{ machine_status_file }}"
  register: status_slurp
  when: status_stat.stat.exists

- name: "Predeploy | Parse do status existente (ou base vazio)"
  ansible.builtin.set_fact:
    status_obj: "{{ (status_slurp.content | b64decode | from_json) if (status_stat.stat.exists | default(false)) else {} }}"

- name: "Predeploy | Escrever status inicial (predeploy:queued) com history append"
  ansible.builtin.copy:
    dest: "{{ machine_status_file }}"
    mode: "0644"
    content: >-
      {{
        (
          status_obj
          | combine({
              "run_id": run_id,
              "stage": stage_name,
              "machine": current_machine,
              "host": (machine_cfg.host | default(machine_cfg.ip | default(''))),
              "package": (machine_cfg.package | default('')),
              "rollback": (machine_cfg.rollback | default('')),
              "deployment_ref": (deployment_ref | default('')),
              "log_path": filestore_log_path,
              "status": "predeploy:queued",
              "timestamp": ansible_date_time.iso8601,
              "history": (
                (status_obj.history | default([]))
                + [ {
                      "run_id": run_id,
                      "stage": stage_name,
                      "status": "predeploy:queued",
                      "timestamp": ansible_date_time.iso8601
                    } ]
              )
            }, recursive=True)
        ) | to_nice_json
      }}
  changed_when: true

# -----------------------------------------------------------------------------
# 9) Preparar diretórios no host remoto
# -----------------------------------------------------------------------------
- name: "Predeploy | Definir diretórios remotos do pipeline"
  ansible.builtin.set_fact:
    deploy_base_dir: "/opt/SoftwareExpress/sitef-pipeline/deploy/components"
    deploy_scripts_dir: "/opt/SoftwareExpress/sitef-pipeline/deploy/scripts"
    deploy_scripts_package_dir: "/opt/SoftwareExpress/sitef-pipeline/deploy/scripts/package"

- name: "Predeploy | Garantir base do pipeline no host"
  become: true
  ansible.builtin.file:
    path: "{{ item }}"
    state: directory
    mode: "0755"
  delegate_to: "{{ current_machine }}"
  loop:
    - "{{ deploy_base_dir }}"
    - "{{ deploy_scripts_dir }}"
    - "{{ deploy_scripts_package_dir }}"

# -----------------------------------------------------------------------------
# 10) Limpar pasta do package scripts e recriar
# -----------------------------------------------------------------------------
- name: "Predeploy | Limpar pasta de scripts do pacote"
  become: true
  ansible.builtin.file:
    path: "{{ deploy_scripts_package_dir }}"
    state: absent
  delegate_to: "{{ current_machine }}"

- name: "Predeploy | Recriar pasta de scripts do pacote"
  become: true
  ansible.builtin.file:
    path: "{{ deploy_scripts_package_dir }}"
    state: directory
    mode: "0755"
  delegate_to: "{{ current_machine }}"

# -----------------------------------------------------------------------------
# 11) Copiar package.yml para /deploy/scripts/package/
# -----------------------------------------------------------------------------
- name: "Predeploy | Copiar package.yml para o host"
  become: true
  ansible.builtin.copy:
    src: "{{ packages_dir }}/{{ machine_cfg.package }}.yml"
    dest: "{{ deploy_scripts_package_dir }}/{{ machine_cfg.package }}.yml"
    mode: "0644"
  delegate_to: "{{ current_machine }}"

# -----------------------------------------------------------------------------
# 12) Garantir diretórios dos componentes + baixar do Nexus
# -----------------------------------------------------------------------------
- name: "Predeploy | Garantir diretórios dos componentes no host"
  become: true
  ansible.builtin.file:
    path: "{{ deploy_base_dir }}/{{ item | dirname }}"
    state: directory
    mode: "0755"
  loop: "{{ package_cfg.components }}"
  delegate_to: "{{ current_machine }}"

- name: "Predeploy | Baixar componentes do Nexus"
  become: true
  ansible.builtin.get_url:
    url: "{{ nexus_base_url.rstrip('/') }}/{{ item }}"
    dest: "{{ deploy_base_dir }}/{{ item }}"
    mode: "0644"
    url_username: "{{ nexus_user | default(omit) }}"
    url_password: "{{ nexus_password | default(omit) }}"
  loop: "{{ package_cfg.components }}"
  delegate_to: "{{ current_machine }}"

# -----------------------------------------------------------------------------
# 13) Copiar scripts do pacote para /deploy/scripts
# -----------------------------------------------------------------------------
- name: "Predeploy | Copiar scripts do pacote para o host"
  become: true
  ansible.builtin.copy:
    src: "{{ scripts_root_dir }}/{{ package_cfg.script }}/"
    dest: "{{ deploy_scripts_dir }}/"
    mode: "0755"
  delegate_to: "{{ current_machine }}"

# -----------------------------------------------------------------------------
# 14) Executar init_parallel.sh na máquina alvo (com tee -a)
# -----------------------------------------------------------------------------
- name: "Predeploy | Executar init_parallel.sh no host (com log + stdout)"
  become: true
  ansible.builtin.shell: |
    set -o pipefail
    cd "{{ deploy_scripts_dir }}"
    /usr/bin/stdbuf -oL -eL /bin/bash -x ./init_parallel.sh 2>&1 | tee -a "{{ deploy_scripts_dir }}/init_parallel.log"
    exit ${PIPESTATUS[0]}
  args:
    executable: /bin/bash
  environment: "{{ merged_env_vars }}"
  delegate_to: "{{ current_machine }}"
  register: init_parallel_result
  ignore_errors: true
  changed_when: true

- name: "Predeploy | Tail do init_parallel.log (sempre)"
  become: true
  ansible.builtin.shell: |
    echo "===== tail -n 800 {{ deploy_scripts_dir }}/init_parallel.log ====="
    tail -n 800 "{{ deploy_scripts_dir }}/init_parallel.log" 2>/dev/null || echo "log não encontrado"
  args:
    executable: /bin/bash
  delegate_to: "{{ current_machine }}"
  register: predeploy_tail
  changed_when: false
  failed_when: false

# -----------------------------------------------------------------------------
# 15) Montar bloco de log + append no pipeline.log (controller)
# -----------------------------------------------------------------------------
- name: "Predeploy | Montar conteúdo do log (bloco predeploy)"
  ansible.builtin.set_fact:
    predeploy_log_block: |
      ---- pipeline predeploy ----
      run_id={{ run_id }}
      deployment_ref={{ deployment_ref | default('') }}
      machine={{ current_machine }}
      host={{ machine_cfg.host | default(machine_cfg.ip | default('')) }}
      stage={{ stage_name }}
      rc={{ init_parallel_result.rc | default(1) }}
      ts={{ ansible_date_time.iso8601 }}

      ---- stdout (ansible) ----
      {{ init_parallel_result.stdout | default('') }}

      ---- stderr (ansible) ----
      {{ init_parallel_result.stderr | default('') }}

      ---- init_parallel.log (tail) ----
      {{ predeploy_tail.stdout | default('') }}
      ---- pipeline predeploy ----

- name: "Predeploy | Append do bloco no pipeline.log (controller)"
  ansible.builtin.blockinfile:
    path: "{{ pipeline_log_file }}"
    marker: ""
    insertafter: EOF
    block: |
      {{ predeploy_log_block }}
  changed_when: true

- name: "Predeploy | Carregar conteúdo completo do pipeline.log (controller)"
  ansible.builtin.set_fact:
    pipeline_log_content_full: "{{ lookup('ansible.builtin.file', pipeline_log_file) }}"

# -----------------------------------------------------------------------------
# 16) Atualizar status final (predeploy:ok / predeploy:error) com history append
# -----------------------------------------------------------------------------
- name: "Predeploy | Ler status.json atual"
  ansible.builtin.slurp:
    path: "{{ machine_status_file }}"
  register: status_after_queued_slurp

- name: "Predeploy | Parse do status atual"
  ansible.builtin.set_fact:
    status_now: "{{ status_after_queued_slurp.content | b64decode | from_json }}"

- name: "Predeploy | Atualizar status final (append em history)"
  ansible.builtin.copy:
    dest: "{{ machine_status_file }}"
    mode: "0644"
    content: >-
      {{
        (
          status_now
          | combine({
              "run_id": run_id,
              "stage": stage_name,
              "status": ("predeploy:ok" if (init_parallel_result.rc | default(1)) == 0 else "predeploy:error"),
              "timestamp": ansible_date_time.iso8601,
              "rc": (init_parallel_result.rc | default(1)),
              "history": (
                (status_now.history | default([]))
                + [ {
                      "run_id": run_id,
                      "stage": stage_name,
                      "status": ("predeploy:ok" if (init_parallel_result.rc | default(1)) == 0 else "predeploy:error"),
                      "rc": (init_parallel_result.rc | default(1)),
                      "timestamp": ansible_date_time.iso8601
                    } ]
              )
            }, recursive=True)
        ) | to_nice_json
      }}
  changed_when: true

# -----------------------------------------------------------------------------
# 17) Upload para Harness File Store (SEMPRE)
# -----------------------------------------------------------------------------
- name: "Predeploy | Upload JSON + LOG para Harness File Store (sempre)"
  ansible.builtin.include_tasks: harness_filestore_upload.yml
  vars:
    stage_name: "{{ stage_name }}"
    current_machine: "{{ current_machine }}"
    machine_status_file: "{{ machine_status_file }}"
    log_content: "{{ pipeline_log_content_full }}"
    status_tag_value: "{{ deployment_ref_lower ~ ':predeploy:' ~ ('ok' if (init_parallel_result.rc | default(1)) == 0 else 'error') }}"
    extra_tags: "{{ [ deployment_ref_lower ~ ':deploy:pending' ] if (init_parallel_result.rc | default(1)) == 0 else [] }}"

# -----------------------------------------------------------------------------
# 18) Falhar pipeline se predeploy deu erro (DEPOIS do upload)
# -----------------------------------------------------------------------------
- name: "Predeploy | Falhar se init_parallel.sh retornou erro (depois do upload)"
  ansible.builtin.fail:
    msg: "PREDEPLOY falhou em {{ current_machine }} (rc={{ init_parallel_result.rc | default(1) }})"
  when: (init_parallel_result.rc | default(1)) != 0

